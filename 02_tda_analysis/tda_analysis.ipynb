{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5f65b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./..') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23be9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gudhi as gd\n",
    "import networkx as nx\n",
    "\n",
    "def compute_average_filtration(G):\n",
    "    \"\"\"\n",
    "    Compute average filtration values for edges of a temporal graph using node timestamps.\n",
    "\n",
    "    Input:\n",
    "    - G: networkx.Graph\n",
    "         Each NODE has a 'timestamp' attribute.\n",
    "    \n",
    "    Output:\n",
    "    - favg: dict mapping edge tuples (u,v) to average filtration value (float)\n",
    "    \"\"\"\n",
    "\n",
    "    def normalize_edge(e):\n",
    "        return tuple(sorted(e))\n",
    "\n",
    "    Se = {normalize_edge(e): 0 for e in G.edges()}\n",
    "    visited = {v: False for v in G.nodes()}\n",
    "    favg = {}\n",
    "\n",
    "    temporal_degree = {v: G.degree(v) for v in G.nodes()}\n",
    "\n",
    "    for v in G.nodes():\n",
    "        Ev = list(G.edges(v))\n",
    "        stack = Ev.copy()\n",
    "\n",
    "        while stack:\n",
    "            e = stack.pop()\n",
    "            e_norm = normalize_edge(e)\n",
    "            u1, u2 = e_norm\n",
    "            t = min(G.nodes[u1]['timestamp'], G.nodes[u2]['timestamp'])\n",
    "\n",
    "            for e_prime in stack:\n",
    "                e_prime_norm = normalize_edge(e_prime)\n",
    "                v1, v2 = e_prime_norm\n",
    "                t_prime = min(G.nodes[v1]['timestamp'], G.nodes[v2]['timestamp'])\n",
    "\n",
    "                delta = abs(t - t_prime)\n",
    "\n",
    "                Se[e_norm] += delta\n",
    "                Se[e_prime_norm] += delta\n",
    "\n",
    "            u = e[1] if e[0] == v else e[0]\n",
    "            if visited[u]:\n",
    "                favg[e_norm] = Se[e_norm] / (temporal_degree[v] + temporal_degree[u])\n",
    "\n",
    "        visited[v] = True\n",
    "\n",
    "    for e in G.edges():\n",
    "        e_norm = normalize_edge(e)\n",
    "        if e_norm not in favg:\n",
    "            u, v = e_norm\n",
    "            favg[e_norm] = Se[e_norm] / (temporal_degree[u] + temporal_degree[v])\n",
    "\n",
    "    return favg\n",
    "\n",
    "\n",
    "\n",
    "def build_simplex_tree_from_graph(G, favg, max_dim=3):\n",
    "    \"\"\"\n",
    "    Build a GUDHI simplex tree from a graph G using average filtration values for edges.\n",
    "\n",
    "    Parameters:\n",
    "    - G: networkx.Graph\n",
    "    - favg: dict mapping edges (u,v) to filtration values (floats)\n",
    "    - max_dim: int, max simplex dimension (3 for up to tetrahedra)\n",
    "    \n",
    "    Returns:\n",
    "    - st: gudhi.SimplexTree object with filtration\n",
    "    \"\"\"\n",
    "    st = gd.SimplexTree()\n",
    "    node_to_id = {node: i for i, node in enumerate(G.nodes())}\n",
    "    \n",
    "    for node, idx in node_to_id.items():\n",
    "        incident_edges = list(G.edges(node))\n",
    "        if incident_edges:\n",
    "            filts = []\n",
    "            for u,v in incident_edges:\n",
    "                edge_norm = (min(u,v), max(u,v))\n",
    "                filt_val = favg.get(edge_norm, float('inf'))\n",
    "                filts.append(filt_val)\n",
    "            vertex_filt = min(filts) if filts else 0.0\n",
    "            if vertex_filt == float('inf'):\n",
    "                vertex_filt = 0.0\n",
    "        else:\n",
    "            vertex_filt = 0.0  \n",
    "            \n",
    "        st.insert([idx], filtration=vertex_filt)\n",
    "    \n",
    "    for u, v in G.edges():\n",
    "        edge_norm = (min(u, v), max(u, v))\n",
    "        idx_u, idx_v = node_to_id[u], node_to_id[v]\n",
    "        filt = favg.get(edge_norm, 0.0)\n",
    "        st.insert([idx_u, idx_v], filtration=filt)\n",
    "    \n",
    "    if max_dim >= 2:\n",
    "        for clique in nx.enumerate_all_cliques(G):\n",
    "            if len(clique) >= 3 and len(clique) <= max_dim + 1:\n",
    "                simplex = [node_to_id[n] for n in clique]\n",
    "                max_filt = 0.0\n",
    "                for i in range(len(simplex)):\n",
    "                    for j in range(i + 1, len(simplex)):\n",
    "                        edge_nodes = (clique[i], clique[j])\n",
    "                        edge_norm = (min(edge_nodes), max(edge_nodes))\n",
    "                        edge_filt = favg.get(edge_norm, 0.0)\n",
    "                        if edge_filt > max_filt:\n",
    "                            max_filt = edge_filt\n",
    "                st.insert(simplex, filtration=max_filt)\n",
    "    \n",
    "    st.initialize_filtration()\n",
    "    return st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e4a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "folder = '../collection/graphs/networkx/concrete'\n",
    "filename = \"graphs_concrete.pkl\"\n",
    "filepath = os.path.join(folder, filename)\n",
    "\n",
    "with open(filepath, 'rb') as f:\n",
    "    graphs_concrete = pickle.load(f)\n",
    "print(f\"Loaded {len(graphs_concrete)} graphs from {filepath}\")\n",
    "\n",
    "folder = '../collection/graphs/networkx/dirt'\n",
    "filename = \"graphs_dirt.pkl\"\n",
    "filepath = os.path.join(folder, filename)\n",
    "\n",
    "with open(filepath, 'rb') as f:\n",
    "    graphs_dirt = pickle.load(f)\n",
    "print(f\"Loaded {len(graphs_dirt)} graphs from {filepath}\")\n",
    "\n",
    "folder = '../collection/graphs/networkx/rocky'\n",
    "filename = \"graphs_rocky.pkl\"\n",
    "filepath = os.path.join(folder, filename)\n",
    "\n",
    "with open(filepath, 'rb') as f:\n",
    "    graphs_rocky = pickle.load(f)\n",
    "print(f\"Loaded {len(graphs_rocky)} graphs from {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e15ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gudhi as gd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import manifold\n",
    "\n",
    "all_graphs = graphs_dirt + graphs_concrete + graphs_rocky\n",
    "num_dirt = len(graphs_dirt)\n",
    "num_concrete = len(graphs_concrete)\n",
    "num_rocky = len(graphs_rocky)\n",
    "total_graphs = len(all_graphs)\n",
    "\n",
    "print(f\"Number of graphs - Dirt: {num_dirt}, Concrete: {num_concrete}, Rocky: {num_rocky}\")\n",
    "\n",
    "persistence_list0 = []\n",
    "persistence_list1 = []\n",
    "\n",
    "for idx, g in enumerate(all_graphs):\n",
    "    filtration = compute_average_filtration(g)  \n",
    "    simplex_tree = build_simplex_tree_from_graph(g, filtration, max_dim=2)  \n",
    "    simplex_tree.persistence()\n",
    "\n",
    "    pd0 = simplex_tree.persistence_intervals_in_dimension(0)\n",
    "    pd1 = simplex_tree.persistence_intervals_in_dimension(1)\n",
    "\n",
    "    persistence_list0.append(pd0)\n",
    "    persistence_list1.append(pd1)\n",
    "\n",
    "def compute_bottleneck_distance_matrix(persistence_list):\n",
    "    l = len(persistence_list)\n",
    "    D = np.full((l, l), np.inf)\n",
    "    for i in range(l):\n",
    "        for j in range(i):\n",
    "            dist = gd.bottleneck_distance(persistence_list[i], persistence_list[j])\n",
    "            D[i, j] = dist\n",
    "            D[j, i] = dist\n",
    "    np.fill_diagonal(D, 0)\n",
    "    return D\n",
    "\n",
    "B0 = compute_bottleneck_distance_matrix(persistence_list0)\n",
    "B1 = compute_bottleneck_distance_matrix(persistence_list1)\n",
    "\n",
    "#Replace infs with fixed large values ---\n",
    "fixed_inf_replacement_B0 = np.max(B0[np.isfinite(B0)]) + 1.0\n",
    "fixed_inf_replacement_B1 = np.max(B1[np.isfinite(B1)]) + 1.0\n",
    "\n",
    "B0[np.isinf(B0)] = fixed_inf_replacement_B0\n",
    "B1[np.isinf(B1)] = fixed_inf_replacement_B1\n",
    "\n",
    "#  Normalize distances ---\n",
    "def normalize_distances(D):\n",
    "    max_val = np.max(D[np.isfinite(D)])\n",
    "    return D / max_val if max_val != 0 else D\n",
    "\n",
    "B0 = normalize_distances(B0)\n",
    "B1 = normalize_distances(B1)\n",
    "\n",
    "\n",
    "print(\"Unique values in B0:\", np.unique(np.round(B0, decimals=4)))\n",
    "print(\"Unique values in B1:\", np.unique(np.round(B1, decimals=4)))\n",
    "\n",
    "# MDS embedding ---\n",
    "def compute_mds_embedding_from_distance_matrix(D):\n",
    "    D = D.copy()\n",
    "    np.fill_diagonal(D, 0)\n",
    "    mds = manifold.MDS(\n",
    "        n_components=2,\n",
    "        max_iter=3000,\n",
    "        eps=1e-9,\n",
    "        dissimilarity=\"precomputed\",\n",
    "        random_state=42\n",
    "    )\n",
    "    return mds.fit_transform(D)\n",
    "\n",
    "pos_h0 = compute_mds_embedding_from_distance_matrix(B0)\n",
    "pos_h1 = compute_mds_embedding_from_distance_matrix(B1)\n",
    "\n",
    "print(f\"pos_h0 shape: {pos_h0.shape}\")\n",
    "print(f\"pos_h1 shape: {pos_h1.shape}\")\n",
    "\n",
    "#  Add jitter to embeddings ---\n",
    "def add_jitter(pos, scale=1e-2):\n",
    "    jitter = np.random.normal(0, scale, pos.shape)\n",
    "    return pos + jitter\n",
    "\n",
    "jitter_scale = 0.01\n",
    "pos_h0_jittered = add_jitter(pos_h0, scale=jitter_scale)\n",
    "pos_h1_jittered = add_jitter(pos_h1, scale=jitter_scale)\n",
    "\n",
    "#  Plot embeddings with jitter ---\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# H0 plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(pos_h0_jittered[:num_dirt, 0], pos_h0_jittered[:num_dirt, 1],\n",
    "            color='green', label='Dirt (H0)', alpha=0.6, edgecolors='k', s=50, marker='o')\n",
    "plt.scatter(pos_h0_jittered[num_dirt:num_dirt+num_concrete, 0], pos_h0_jittered[num_dirt:num_dirt+num_concrete, 1],\n",
    "            color='red', label='Concrete (H0)', alpha=0.6, edgecolors='k', s=50, marker='s')\n",
    "plt.scatter(pos_h0_jittered[num_dirt+num_concrete:, 0], pos_h0_jittered[num_dirt+num_concrete:, 1],\n",
    "            color='blue', label='Rocky (H0)', alpha=0.6, edgecolors='k', s=50, marker='^')\n",
    "plt.title('MDS Plot of Bottleneck Distances (H0)')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(pos_h1_jittered[:num_dirt, 0], pos_h1_jittered[:num_dirt, 1],\n",
    "            color='green', label='Dirt (H1)', alpha=0.6, edgecolors='k', s=50, marker='o')\n",
    "plt.scatter(pos_h1_jittered[num_dirt:num_dirt+num_concrete, 0], pos_h1_jittered[num_dirt:num_dirt+num_concrete, 1],\n",
    "            color='red', label='Concrete (H1)', alpha=0.6, edgecolors='k', s=50, marker='s')\n",
    "plt.scatter(pos_h1_jittered[num_dirt+num_concrete:, 0], pos_h1_jittered[num_dirt+num_concrete:, 1],\n",
    "            color='blue', label='Rocky (H1)', alpha=0.6, edgecolors='k', s=50, marker='^')\n",
    "plt.title('MDS Plot of Bottleneck Distances (H1)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd7c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gudhi as gd\n",
    "import gudhi.representations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Split persistence diagrams by class ---\n",
    "dirt_diags_0 = persistence_list0[:num_dirt]\n",
    "concrete_diags_0 = persistence_list0[num_dirt:num_dirt+num_concrete]\n",
    "rocky_diags_0 = persistence_list0[num_dirt+num_concrete:]\n",
    "\n",
    "dirt_diags_1 = persistence_list1[:num_dirt]\n",
    "concrete_diags_1 = persistence_list1[num_dirt:num_dirt+num_concrete]\n",
    "rocky_diags_1 = persistence_list1[num_dirt+num_concrete:]\n",
    "\n",
    "\n",
    "remove_infinity = lambda barcode: np.array([bar for bar in barcode if bar[1] != np.inf])\n",
    "\n",
    "dirt_diags_0_finite = list(map(remove_infinity, dirt_diags_0))\n",
    "concrete_diags_0_finite = list(map(remove_infinity, concrete_diags_0))\n",
    "rocky_diags_0_finite = list(map(remove_infinity, rocky_diags_0))\n",
    "\n",
    "dirt_diags_1_finite = list(map(remove_infinity, dirt_diags_1))\n",
    "concrete_diags_1_finite = list(map(remove_infinity, concrete_diags_1))\n",
    "rocky_diags_1_finite = list(map(remove_infinity, rocky_diags_1))\n",
    "\n",
    "\n",
    "def fix_diagram_shape(diagram):\n",
    "    arr = np.array(diagram)\n",
    "    if arr.size == 0:\n",
    "        # Empty diagram, shape (0, 2)\n",
    "        return arr.reshape(0, 2)\n",
    "    if arr.ndim == 1:\n",
    "        # Single bar, reshape to (1, 2)\n",
    "        arr = arr.reshape(1, 2)\n",
    "    return arr\n",
    "\n",
    "dirt_diags_0_finite = [fix_diagram_shape(d) for d in dirt_diags_0_finite]\n",
    "concrete_diags_0_finite = [fix_diagram_shape(d) for d in concrete_diags_0_finite]\n",
    "rocky_diags_0_finite = [fix_diagram_shape(d) for d in rocky_diags_0_finite]\n",
    "\n",
    "dirt_diags_1_finite = [fix_diagram_shape(d) for d in dirt_diags_1_finite]\n",
    "concrete_diags_1_finite = [fix_diagram_shape(d) for d in concrete_diags_1_finite]\n",
    "rocky_diags_1_finite = [fix_diagram_shape(d) for d in rocky_diags_1_finite]\n",
    "\n",
    "\n",
    "#Filter out empty diagrams (0 bars) ---\n",
    "def filter_nonempty(barcodes):\n",
    "    return [b for b in barcodes if b.shape[0] > 0]\n",
    "\n",
    "dirt_diags_0_finite = filter_nonempty(dirt_diags_0_finite)\n",
    "concrete_diags_0_finite = filter_nonempty(concrete_diags_0_finite)\n",
    "rocky_diags_0_finite = filter_nonempty(rocky_diags_0_finite)\n",
    "\n",
    "dirt_diags_1_finite = filter_nonempty(dirt_diags_1_finite)\n",
    "concrete_diags_1_finite = filter_nonempty(concrete_diags_1_finite)\n",
    "rocky_diags_1_finite = filter_nonempty(rocky_diags_1_finite)\n",
    "\n",
    "\n",
    "#Compute Persistent Entropy (PE) ---\n",
    "\n",
    "PE = gd.representations.Entropy()\n",
    "\n",
    "pe_dirt_0 = PE.fit_transform(dirt_diags_0_finite)\n",
    "pe_concrete_0 = PE.fit_transform(concrete_diags_0_finite)\n",
    "pe_rocky_0 = PE.fit_transform(rocky_diags_0_finite)\n",
    "\n",
    "pe_dirt_1 = PE.fit_transform(dirt_diags_1_finite)\n",
    "pe_concrete_1 = PE.fit_transform(concrete_diags_1_finite)\n",
    "pe_rocky_1 = PE.fit_transform(rocky_diags_1_finite)\n",
    "\n",
    "\n",
    "#Plot Persistent Entropy boxplots ---\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.boxplot([pe_dirt_0[:,0], pe_concrete_0[:,0], pe_rocky_0[:,0]], labels=['Dirt H0', 'Concrete H0', 'Rocky H0'])\n",
    "plt.title('Persistent Entropy (H0)')\n",
    "plt.ylabel('Persistent Entropy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([pe_dirt_1[:,0], pe_concrete_1[:,0], pe_rocky_1[:,0]], labels=['Dirt H1', 'Concrete H1', 'Rocky H1'])\n",
    "plt.title('Persistent Entropy (H1)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def print_summary(name, data):\n",
    "    print(f\"{name}: mean={np.mean(data):.3f}, std={np.std(data):.3f}, n={len(data)}\")\n",
    "\n",
    "print_summary(\"Dirt H0 PE\", pe_dirt_0)\n",
    "print_summary(\"Concrete H0 PE\", pe_concrete_0)\n",
    "print_summary(\"Rocky H0 PE\", pe_rocky_0)\n",
    "\n",
    "print_summary(\"Dirt H1 PE\", pe_dirt_1)\n",
    "print_summary(\"Concrete H1 PE\", pe_concrete_1)\n",
    "print_summary(\"Rocky H1 PE\", pe_rocky_1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e29561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some small random noise for jitter to avoid overplotting\n",
    "jitter_strength = 0.02\n",
    "pos_h0_jittered = pos_h0 + jitter_strength * np.random.randn(*pos_h0.shape)\n",
    "pos_h1_jittered = pos_h1 + jitter_strength * np.random.randn(*pos_h1.shape)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# H0 plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(pos_h0_jittered[:num_dirt, 0], pos_h0_jittered[:num_dirt, 1],\n",
    "            color='green', label='Dirt (H0)', alpha=0.6, edgecolors='k', s=50, marker='o')\n",
    "plt.scatter(pos_h0_jittered[num_dirt:num_dirt+num_concrete, 0], pos_h0_jittered[num_dirt:num_dirt+num_concrete, 1],\n",
    "            color='red', label='Concrete (H0)', alpha=0.6, edgecolors='k', s=50, marker='s')\n",
    "plt.scatter(pos_h0_jittered[num_dirt+num_concrete:, 0], pos_h0_jittered[num_dirt+num_concrete:, 1],\n",
    "            color='blue', label='Rocky (H0)', alpha=0.6, edgecolors='k', s=50, marker='^')\n",
    "plt.title('MDS Plot of Bottleneck Distances (H0)')\n",
    "plt.legend()\n",
    "\n",
    "# H1 plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(pos_h1_jittered[:num_dirt, 0], pos_h1_jittered[:num_dirt, 1],\n",
    "            color='green', label='Dirt (H1)', alpha=0.6, edgecolors='k', s=50, marker='o')\n",
    "plt.scatter(pos_h1_jittered[num_dirt:num_dirt+num_concrete, 0], pos_h1_jittered[num_dirt:num_dirt+num_concrete, 1],\n",
    "            color='red', label='Concrete (H1)', alpha=0.6, edgecolors='k', s=50, marker='s')\n",
    "plt.scatter(pos_h1_jittered[num_dirt+num_concrete:, 0], pos_h1_jittered[num_dirt+num_concrete:, 1],\n",
    "            color='blue', label='Rocky (H1)', alpha=0.6, edgecolors='k', s=50, marker='^')\n",
    "plt.title('MDS Plot of Bottleneck Distances (H1)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295410a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gudhi as gd\n",
    "import gudhi.representations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "remove_infinity = lambda barcode: np.array([bar for bar in barcode if bar[1] != np.inf])\n",
    "\n",
    "dirt_diags_0_finite = list(map(remove_infinity, dirt_diags_0))\n",
    "concrete_diags_0_finite = list(map(remove_infinity, concrete_diags_0))\n",
    "rocky_diags_0_finite = list(map(remove_infinity, rocky_diags_0))\n",
    "\n",
    "dirt_diags_1_finite = list(map(remove_infinity, dirt_diags_1))\n",
    "concrete_diags_1_finite = list(map(remove_infinity, concrete_diags_1))\n",
    "rocky_diags_1_finite = list(map(remove_infinity, rocky_diags_1))\n",
    "\n",
    "def fix_diagram_shape(diagram):\n",
    "    arr = np.array(diagram)\n",
    "    if arr.size == 0:\n",
    "        return arr.reshape(0, 2)\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr.reshape(1, 2)\n",
    "    return arr\n",
    "\n",
    "dirt_diags_0_finite = [fix_diagram_shape(d) for d in dirt_diags_0_finite]\n",
    "concrete_diags_0_finite = [fix_diagram_shape(d) for d in concrete_diags_0_finite]\n",
    "rocky_diags_0_finite = [fix_diagram_shape(d) for d in rocky_diags_0_finite]\n",
    "\n",
    "dirt_diags_1_finite = [fix_diagram_shape(d) for d in dirt_diags_1_finite]\n",
    "concrete_diags_1_finite = [fix_diagram_shape(d) for d in concrete_diags_1_finite]\n",
    "rocky_diags_1_finite = [fix_diagram_shape(d) for d in rocky_diags_1_finite]\n",
    "\n",
    "def filter_nonempty(barcodes):\n",
    "    return [b for b in barcodes if b.shape[0] > 0]\n",
    "\n",
    "dirt_diags_0_finite = filter_nonempty(dirt_diags_0_finite)\n",
    "concrete_diags_0_finite = filter_nonempty(concrete_diags_0_finite)\n",
    "rocky_diags_0_finite = filter_nonempty(rocky_diags_0_finite)\n",
    "\n",
    "dirt_diags_1_finite = filter_nonempty(dirt_diags_1_finite)\n",
    "concrete_diags_1_finite = filter_nonempty(concrete_diags_1_finite)\n",
    "rocky_diags_1_finite = filter_nonempty(rocky_diags_1_finite)\n",
    "\n",
    "PE = gd.representations.Entropy()\n",
    "\n",
    "pe_dirt_0 = PE.fit_transform(dirt_diags_0_finite)\n",
    "pe_concrete_0 = PE.fit_transform(concrete_diags_0_finite)\n",
    "pe_rocky_0 = PE.fit_transform(rocky_diags_0_finite)\n",
    "\n",
    "pe_dirt_1 = PE.fit_transform(dirt_diags_1_finite)\n",
    "pe_concrete_1 = PE.fit_transform(concrete_diags_1_finite)\n",
    "pe_rocky_1 = PE.fit_transform(rocky_diags_1_finite)\n",
    "\n",
    "num_dirt = len(pe_dirt_0)\n",
    "num_concrete = len(pe_concrete_0)\n",
    "num_rocky = len(pe_rocky_0)\n",
    "\n",
    "max_death_0 = max(\n",
    "    max(bar[1] for barcode in dirt_diags_0_finite for bar in barcode),\n",
    "    max(bar[1] for barcode in concrete_diags_0_finite for bar in barcode),\n",
    "    max(bar[1] for barcode in rocky_diags_0_finite for bar in barcode),\n",
    ")\n",
    "\n",
    "max_death_1 = max(\n",
    "    max(bar[1] for barcode in dirt_diags_1_finite for bar in barcode),\n",
    "    max(bar[1] for barcode in concrete_diags_1_finite for bar in barcode),\n",
    "    max(bar[1] for barcode in rocky_diags_1_finite for bar in barcode),\n",
    ")\n",
    "\n",
    "ES0 = gd.representations.Entropy(\n",
    "    mode='vector', sample_range=[0, max_death_0], resolution=151, normalized=False\n",
    ")\n",
    "ES1 = gd.representations.Entropy(\n",
    "    mode='vector', sample_range=[0, max_death_1], resolution=151, normalized=False\n",
    ")\n",
    "\n",
    "es_dirt_0 = ES0.fit_transform(dirt_diags_0_finite)\n",
    "es_concrete_0 = ES0.fit_transform(concrete_diags_0_finite)\n",
    "es_rocky_0 = ES0.fit_transform(rocky_diags_0_finite)\n",
    "\n",
    "es_dirt_1 = ES1.fit_transform(dirt_diags_1_finite)\n",
    "es_concrete_1 = ES1.fit_transform(concrete_diags_1_finite)\n",
    "es_rocky_1 = ES1.fit_transform(rocky_diags_1_finite)\n",
    "\n",
    "x_vals_0 = np.linspace(0, max_death_0, 151)\n",
    "x_vals = np.linspace(0, max_death_1, 151)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "axs[0, 0].boxplot([pe_dirt_0[:, 0], pe_concrete_0[:, 0], pe_rocky_0[:, 0]], labels=['Dirt H0', 'Concrete H0', 'Rocky H0'])\n",
    "axs[0, 0].set_title('Persistent Entropy (H0)')\n",
    "axs[0, 0].set_ylabel('Persistent Entropy')\n",
    "\n",
    "axs[0, 1].boxplot([pe_dirt_1[:, 0], pe_concrete_1[:, 0], pe_rocky_1[:, 0]], labels=['Dirt H1', 'Concrete H1', 'Rocky H1'])\n",
    "axs[0, 1].set_title('Persistent Entropy (H1)')\n",
    "\n",
    "axs[0, 2].scatter(pos_h0_jittered[:num_dirt, 0], pos_h0_jittered[:num_dirt, 1], color='green', label='Dirt', alpha=0.6, edgecolors='k', s=50, marker='o')\n",
    "axs[0, 2].scatter(pos_h0_jittered[num_dirt:num_dirt+num_concrete, 0], pos_h0_jittered[num_dirt:num_dirt+num_concrete, 1], color='red', label='Concrete', alpha=0.6, edgecolors='k', s=50, marker='s')\n",
    "axs[0, 2].scatter(pos_h0_jittered[num_dirt+num_concrete:, 0], pos_h0_jittered[num_dirt+num_concrete:, 1], color='blue', label='Rocky', alpha=0.6, edgecolors='k', s=50, marker='^')\n",
    "axs[0, 2].set_title('MDS Plot of Bottleneck Distances (H0)')\n",
    "axs[0, 2].legend()\n",
    "\n",
    "min_len_h0 = min(len(x_vals_0), es_dirt_0.shape[1])\n",
    "axs[1, 0].plot(x_vals_0[:min_len_h0], np.mean(es_dirt_0, axis=0)[:min_len_h0], label='Dirt H0')\n",
    "axs[1, 0].plot(x_vals_0[:min_len_h0], np.mean(es_concrete_0, axis=0)[:min_len_h0], label='Concrete H0')\n",
    "axs[1, 0].plot(x_vals_0[:min_len_h0], np.mean(es_rocky_0, axis=0)[:min_len_h0], label='Rocky H0')\n",
    "axs[1, 0].set_title('Entropy Summary (H0)')\n",
    "axs[1, 0].set_xlabel('Filtration value')\n",
    "axs[1, 0].set_ylabel('Entropy')\n",
    "axs[1, 0].legend()\n",
    "\n",
    "min_len_h1 = min(len(x_vals), es_dirt_1.shape[1])\n",
    "axs[1, 1].plot(x_vals[:min_len_h1], np.mean(es_dirt_1, axis=0)[:min_len_h1], label='Dirt H1')\n",
    "axs[1, 1].plot(x_vals[:min_len_h1], np.mean(es_concrete_1, axis=0)[:min_len_h1], label='Concrete H1')\n",
    "axs[1, 1].plot(x_vals[:min_len_h1], np.mean(es_rocky_1, axis=0)[:min_len_h1], label='Rocky H1')\n",
    "axs[1, 1].set_title('Entropy Summary (H1)')\n",
    "axs[1, 1].set_xlabel('Filtration value')\n",
    "axs[1, 1].set_ylabel('Entropy')\n",
    "axs[1, 1].legend()\n",
    "\n",
    "axs[1, 2].scatter(pos_h1_jittered[:num_dirt, 0], pos_h1_jittered[:num_dirt, 1], color='green', label='Dirt', alpha=0.6, edgecolors='k', s=50, marker='o')\n",
    "axs[1, 2].scatter(pos_h1_jittered[num_dirt:num_dirt+num_concrete, 0], pos_h1_jittered[num_dirt:num_dirt+num_concrete, 1], color='red', label='Concrete', alpha=0.6, edgecolors='k', s=50, marker='s')\n",
    "axs[1, 2].scatter(pos_h1_jittered[num_dirt+num_concrete:, 0], pos_h1_jittered[num_dirt+num_concrete:, 1], color='blue', label='Rocky', alpha=0.6, edgecolors='k', s=50, marker='^')\n",
    "axs[1, 2].set_title('MDS Plot of Bottleneck Distances (H1)')\n",
    "axs[1, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tda_ml)",
   "language": "python",
   "name": "tda_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
