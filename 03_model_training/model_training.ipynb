{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3301fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./..')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fabcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "\n",
    "def map_nodes_to_ids(g):\n",
    "    \"\"\"\n",
    "    Maps tuple-based nodes in a NetworkX graph to integer node IDs starting from 1.\n",
    "\n",
    "    Returns:\n",
    "        mapped_edges (list of [int, int]): edges with integer node IDs starting at 1\n",
    "        node_to_id (dict): original node -> integer ID\n",
    "        num_nodes (int): number of unique nodes\n",
    "    \"\"\"\n",
    "    node_list = list(g.nodes)\n",
    "    node_to_id = {node: idx + 1 for idx, node in enumerate(node_list)}\n",
    "    \n",
    "    mapped_edges = []\n",
    "    for u, v in g.edges():\n",
    "        uid = node_to_id[u]\n",
    "        vid = node_to_id[v]\n",
    "        mapped_edges.append([uid, vid])\n",
    "    \n",
    "    return mapped_edges, node_to_id, len(node_list)\n",
    "\n",
    "def convert_nx_to_pyg(graphs_nx):\n",
    "    graphs_pyg = []\n",
    "    \n",
    "    for g in graphs_nx:\n",
    "        node_features = [\n",
    "            [data['pitch'], data['timestamp']]\n",
    "            for _, data in g.nodes(data=True)\n",
    "        ]\n",
    "        \n",
    "        x = torch.zeros((len(node_features) + 1, 2))  \n",
    "        x[1:] = torch.tensor(node_features, dtype=torch.float)  \n",
    "        \n",
    "        edge_index = torch.tensor(list(g.edges())).long().t() + 1\n",
    "        edge_attr = torch.ones(edge_index.shape[1], 1)\n",
    "\n",
    "        data = Data(\n",
    "            x=x,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr,\n",
    "            y=torch.tensor([g.graph.get('label', -1)])\n",
    "        )\n",
    "\n",
    "        if 'pi' in g.graph:\n",
    "            data.pi = torch.tensor(g.graph['pi'], dtype=torch.float)\n",
    "\n",
    "        graphs_pyg.append(data)\n",
    "    \n",
    "    return graphs_pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed84e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "filepath = \"../collection/graphs/networkx/concrete/graphs_concrete.pkl\"\n",
    "\n",
    "\n",
    "with open(filepath, 'rb') as f:\n",
    "    graphs_concrete = pickle.load(f)\n",
    "print(f\"Loaded {len(graphs_concrete)} graphs from {filepath}\")\n",
    "\n",
    "\n",
    "filepath= '../collection/graphs/networkx/rocky/graphs_rocky.pkl'\n",
    "filename = \"graphs_rocky.pkl\"\n",
    "\n",
    "with open(filepath, 'rb') as f:\n",
    "    graphs_rocky = pickle.load(f)\n",
    "print(f\"Loaded {len(graphs_rocky)} graphs from {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1551fa",
   "metadata": {},
   "source": [
    "## TDA code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd39dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gudhi.representations import PersistenceImage\n",
    "import numpy as np\n",
    "import gudhi as gd\n",
    "import networkx as nx\n",
    "import torch\n",
    "\n",
    "\n",
    "def compute_average_filtration(G):\n",
    "    \"\"\"\n",
    "    Compute average filtration values for edges of a temporal graph using node timestamps.\n",
    "\n",
    "    Input:\n",
    "    - G: networkx.Graph\n",
    "         Each NODE has a 'timestamp' attribute.\n",
    "    \n",
    "    Output:\n",
    "    - favg: dict mapping edge tuples (u,v) to average filtration value (float)\n",
    "    \"\"\"\n",
    "\n",
    "    def normalize_edge(e):\n",
    "        return tuple(sorted(e))\n",
    "\n",
    "    Se = {normalize_edge(e): 0 for e in G.edges()}\n",
    "    visited = {v: False for v in G.nodes()}\n",
    "    favg = {}\n",
    "\n",
    "    temporal_degree = {v: G.degree(v) for v in G.nodes()}\n",
    "\n",
    "    for v in G.nodes():\n",
    "        Ev = list(G.edges(v))\n",
    "        stack = Ev.copy()\n",
    "\n",
    "        while stack:\n",
    "            e = stack.pop()\n",
    "            e_norm = normalize_edge(e)\n",
    "            u1, u2 = e_norm\n",
    "            t = min(G.nodes[u1]['timestamp'], G.nodes[u2]['timestamp'])\n",
    "\n",
    "            for e_prime in stack:\n",
    "                e_prime_norm = normalize_edge(e_prime)\n",
    "                v1, v2 = e_prime_norm\n",
    "                t_prime = min(G.nodes[v1]['timestamp'], G.nodes[v2]['timestamp'])\n",
    "\n",
    "                delta = abs(t - t_prime)\n",
    "\n",
    "                Se[e_norm] += delta\n",
    "                Se[e_prime_norm] += delta\n",
    "\n",
    "            u = e[1] if e[0] == v else e[0]\n",
    "            if visited[u]:\n",
    "                favg[e_norm] = Se[e_norm] / (temporal_degree[v] + temporal_degree[u])\n",
    "\n",
    "        visited[v] = True\n",
    "\n",
    "    for e in G.edges():\n",
    "        e_norm = normalize_edge(e)\n",
    "        if e_norm not in favg:\n",
    "            u, v = e_norm\n",
    "            favg[e_norm] = Se[e_norm] / (temporal_degree[u] + temporal_degree[v])\n",
    "\n",
    "    return favg\n",
    "\n",
    "\n",
    "\n",
    "def build_simplex_tree_from_graph(G, favg, max_dim=3):\n",
    "    \"\"\"\n",
    "    Build a GUDHI simplex tree from a graph G using average filtration values for edges.\n",
    "\n",
    "    Parameters:\n",
    "    - G: networkx.Graph\n",
    "    - favg: dict mapping edges (u,v) to filtration values (floats)\n",
    "    - max_dim: int, max simplex dimension (3 for up to tetrahedra)\n",
    "    \n",
    "    Returns:\n",
    "    - st: gudhi.SimplexTree object with filtration\n",
    "    \"\"\"\n",
    "    st = gd.SimplexTree()\n",
    "    node_to_id = {node: i for i, node in enumerate(G.nodes())}\n",
    "    \n",
    "    for node, idx in node_to_id.items():\n",
    "        incident_edges = list(G.edges(node))\n",
    "        if incident_edges:\n",
    "            filts = []\n",
    "            for u,v in incident_edges:\n",
    "                edge_norm = (min(u,v), max(u,v))\n",
    "                filt_val = favg.get(edge_norm, float('inf'))\n",
    "                filts.append(filt_val)\n",
    "            vertex_filt = min(filts) if filts else 0.0\n",
    "            if vertex_filt == float('inf'):\n",
    "                vertex_filt = 0.0\n",
    "        else:\n",
    "            vertex_filt = 0.0  \n",
    "            \n",
    "        st.insert([idx], filtration=vertex_filt)\n",
    "    \n",
    "    for u, v in G.edges():\n",
    "        edge_norm = (min(u, v), max(u, v))\n",
    "        idx_u, idx_v = node_to_id[u], node_to_id[v]\n",
    "        filt = favg.get(edge_norm, 0.0)\n",
    "        st.insert([idx_u, idx_v], filtration=filt)\n",
    "    \n",
    "    if max_dim >= 2:\n",
    "        for clique in nx.enumerate_all_cliques(G):\n",
    "            if len(clique) >= 3 and len(clique) <= max_dim + 1:\n",
    "                simplex = [node_to_id[n] for n in clique]\n",
    "                max_filt = 0.0\n",
    "                for i in range(len(simplex)):\n",
    "                    for j in range(i + 1, len(simplex)):\n",
    "                        edge_nodes = (clique[i], clique[j])\n",
    "                        edge_norm = (min(edge_nodes), max(edge_nodes))\n",
    "                        edge_filt = favg.get(edge_norm, 0.0)\n",
    "                        if edge_filt > max_filt:\n",
    "                            max_filt = edge_filt\n",
    "                st.insert(simplex, filtration=max_filt)\n",
    "    \n",
    "    st.initialize_filtration()\n",
    "    return st\n",
    "\n",
    "def compute_persistence_images_for_graphs(\n",
    "    graphs,\n",
    "    max_simplex_dim=3,\n",
    "    pi_resolution=[20, 20],\n",
    "    pi_bandwidth=0.1,\n",
    "    pi_im_range=[0, 1, 0, 1]\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    - diagrams: list of persistence diagrams (numpy arrays of [birth, persistence])\n",
    "    - vectors: list of persistence image flattened vectors\n",
    "    - pi_transformer: fitted PersistenceImage\n",
    "    \"\"\"\n",
    "    diagrams = []\n",
    "\n",
    "    for G in graphs:\n",
    "        favg = compute_average_filtration(G)\n",
    "        st = build_simplex_tree_from_graph(G, favg, max_dim=max_simplex_dim)\n",
    "        diag = st.persistence()\n",
    "\n",
    "        points = []\n",
    "        for dim, (birth, death) in diag:\n",
    "            if death != float('inf'):\n",
    "                points.append([birth, death - birth])\n",
    "\n",
    "        diag_array = np.array(points).reshape(-1, 2)  # ensures shape (0, 2) if empty\n",
    "        diagrams.append(diag_array)\n",
    "\n",
    "    # Filter out diagrams that are empty or not 2D\n",
    "    valid_diagrams = []\n",
    "    valid_indices = []\n",
    "    for i, dgm in enumerate(diagrams):\n",
    "        if dgm.ndim == 2 and dgm.shape[1] == 2 and len(dgm) > 0:\n",
    "            valid_diagrams.append(dgm)\n",
    "            valid_indices.append(i)\n",
    "\n",
    "    pi = PersistenceImage(\n",
    "        bandwidth=pi_bandwidth,\n",
    "        weight=lambda x: x[1],\n",
    "        resolution=pi_resolution,\n",
    "        im_range=pi_im_range\n",
    "    )\n",
    "\n",
    "    # Handle case with no valid diagrams\n",
    "    if valid_diagrams:\n",
    "        pi.fit(valid_diagrams)\n",
    "        vec_dim = np.prod(pi_resolution)\n",
    "        vectors = []\n",
    "        for i, dgm in enumerate(diagrams):\n",
    "            if i in valid_indices:\n",
    "                vec = pi.transform([dgm])[0]\n",
    "            else:\n",
    "                vec = np.zeros(vec_dim)\n",
    "            vectors.append(vec)\n",
    "    else:\n",
    "        vec_dim = np.prod(pi_resolution)\n",
    "        vectors = [np.zeros(vec_dim) for _ in diagrams]\n",
    "\n",
    "    return diagrams, vectors, pi\n",
    "\n",
    "\n",
    "def add_graph_labels(graphs, label):\n",
    "    \"\"\"\n",
    "    Adds a graph-level label as data.y for each graph in the list.\n",
    "\n",
    "    Args:\n",
    "        graphs (list of PyG Data): list of graphs\n",
    "        label (int): graph-level label\n",
    "\n",
    "    Returns:\n",
    "        list of PyG Data with data.y set to label\n",
    "    \"\"\"\n",
    "    for g in graphs:\n",
    "        g.y = torch.tensor([label], dtype=torch.long)  \n",
    "    return graphs\n",
    "\n",
    "\n",
    "def remap_node_indices(data_list, preserve_original_ids=False):\n",
    "    new_data_list = []\n",
    "\n",
    "    for data in data_list:\n",
    "        edge_index = data.edge_index\n",
    "        all_nodes = torch.unique(edge_index)\n",
    "\n",
    "        id_map = {old.item(): new for new, old in enumerate(all_nodes)}\n",
    "\n",
    "        new_edge_index = torch.stack([\n",
    "            torch.tensor([id_map[i.item()] for i in edge_index[0]]),\n",
    "            torch.tensor([id_map[i.item()] for i in edge_index[1]])\n",
    "        ], dim=0)\n",
    "\n",
    "        if hasattr(data, 'x') and data.x is not None:\n",
    "            x_dim = data.x.size(1)\n",
    "            max_index = int(edge_index.max().item()) + 1\n",
    "            if data.x.size(0) < max_index:\n",
    "                padding = torch.zeros((max_index - data.x.size(0), x_dim), dtype=data.x.dtype)\n",
    "                data.x = torch.cat([data.x, padding], dim=0)\n",
    "\n",
    "            x = torch.stack([data.x[old] for old in all_nodes])\n",
    "        else:\n",
    "            x = None\n",
    "\n",
    "        new_data = Data(x=x, edge_index=new_edge_index, y=data.y)\n",
    "\n",
    "        if hasattr(data, 'pi'):\n",
    "            new_data.pi = data.pi\n",
    "\n",
    "        if preserve_original_ids:\n",
    "            new_data.original_ids = all_nodes\n",
    "\n",
    "        new_data_list.append(new_data)\n",
    "\n",
    "    return new_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8760ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagrams_concrete, vectors_concrete, pi_concrete = compute_persistence_images_for_graphs(graphs_concrete)\n",
    "for G, vec in zip(graphs_concrete, vectors_concrete):\n",
    "    G.graph['pi'] = vec\n",
    "\n",
    "diagrams_rocky, vectors_rocky, pi_rocky = compute_persistence_images_for_graphs(graphs_rocky)\n",
    "for G, vec in zip(graphs_rocky, vectors_rocky):\n",
    "    G.graph['pi'] = vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0813d2",
   "metadata": {},
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc66a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_concrete_pyg = convert_nx_to_pyg(graphs_concrete)\n",
    "graphs_rocky_pyg = convert_nx_to_pyg(graphs_rocky)\n",
    "\n",
    "\n",
    "graphs_concrete_pyg = remap_node_indices(graphs_concrete_pyg)\n",
    "graphs_rocky_pyg = remap_node_indices(graphs_rocky_pyg)\n",
    "\n",
    "\n",
    "graphs_concrete_pyg = add_graph_labels(graphs_concrete_pyg, label=0)\n",
    "graphs_rocky_pyg = add_graph_labels(graphs_rocky_pyg, label=1)\n",
    "\n",
    "def combine_graphs(graphs_label_dict):\n",
    "    all_graphs = []\n",
    "    for graphs in graphs_label_dict.values():\n",
    "        all_graphs.extend(graphs)\n",
    "    return all_graphs\n",
    "\n",
    "graphs_dict_with_labels = {\n",
    "    0: graphs_concrete_pyg,  # label 0\n",
    "    1: graphs_rocky_pyg      # label 1\n",
    "}\n",
    "\n",
    "all_graphs = combine_graphs(graphs_dict_with_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bba773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_graphs(graphs, test_size=0.2, val_size=0.25, random_state=42):\n",
    "    \"\"\"\n",
    "    Split PyG graph objects into train, val, and test sets using stratified labels inside the graphs.\n",
    "\n",
    "    Args:\n",
    "        graphs (list): List of PyG Data objects. Each must have a `y` attribute (scalar label).\n",
    "        test_size (float): Proportion of dataset to include in test split.\n",
    "        val_size (float): Proportion of trainval set to include in validation split.\n",
    "        random_state (int): Seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        dict: {\"train\": [...], \"val\": [...], \"test\": [...]}\n",
    "    \"\"\"\n",
    "    labels = [int(g.y.item()) for g in graphs]  \n",
    "    graphs_trainval, graphs_test = train_test_split(\n",
    "        graphs, test_size=test_size, stratify=labels, random_state=random_state\n",
    "    )\n",
    "\n",
    "    labels_trainval = [int(g.y.item()) for g in graphs_trainval]\n",
    "    graphs_train, graphs_val = train_test_split(\n",
    "        graphs_trainval, test_size=val_size, stratify=labels_trainval, random_state=random_state\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"train\": graphs_train,\n",
    "        \"val\": graphs_val,\n",
    "        \"test\": graphs_test\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5330ffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = split_graphs(all_graphs, test_size=0.2, val_size=0.25, random_state=42)\n",
    "\n",
    "train_graphs = splits[\"train\"]\n",
    "val_graphs = splits[\"val\"]\n",
    "test_graphs = splits[\"test\"]\n",
    "\n",
    "print(f\"Train: {len(train_graphs)}\")\n",
    "print(f\"Validation: {len(val_graphs)}\")\n",
    "print(f\"Test: {len(test_graphs)}\")\n",
    "\n",
    "sample = train_graphs[0]\n",
    "print(f\"Node dim: {sample.x.shape}\")  \n",
    "print(type(all_graphs[0]))\n",
    "print(all_graphs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6415361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_graphs, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_graphs, batch_size=4)\n",
    "test_loader = DataLoader(test_graphs, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc5b954",
   "metadata": {},
   "source": [
    "## TGAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf4cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import logging\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import torch\n",
    "from gudhi.representations import PersistenceImage\n",
    "\n",
    "\n",
    "class StandardizeDimensions(nn.Module):\n",
    "    \"\"\"Ensures inputs are always [batch, seq_len, features] or [batch, features]\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x, min_dims=2):\n",
    "        if isinstance(x, (list, tuple)):\n",
    "            return [self.forward(tensor, min_dims) for tensor in x]\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x)\n",
    "        while x.dim() < min_dims:\n",
    "            x = x.unsqueeze(0)\n",
    "        if x.dim() == 2:\n",
    "            return x.unsqueeze(1) if min_dims >= 3 else x\n",
    "        elif x.dim() == 3:  \n",
    "            return x\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected shape {x.shape}. Max 3D tensors supported\")\n",
    "\n",
    "\n",
    "class MergeLayer(nn.Module):\n",
    "    def __init__(self, dim1, dim2, dim3, dim4):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim1 + dim2, dim3)\n",
    "        self.fc2 = nn.Linear(dim3, dim4)\n",
    "        self.act = nn.ReLU()\n",
    "        nn.init.xavier_normal_(self.fc1.weight)\n",
    "        nn.init.xavier_normal_(self.fc2.weight)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        h = self.act(self.fc1(x))\n",
    "        return self.fc2(h)\n",
    "\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, temperature, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        if q.dim() == 2:\n",
    "            q = q.unsqueeze(1)\n",
    "        if k.dim() == 2:\n",
    "            k = k.unsqueeze(1)\n",
    "        if v.dim() == 2:\n",
    "            v = v.unsqueeze(1)\n",
    "            \n",
    "        attn = torch.bmm(q, k.transpose(1, 2)) / self.temperature\n",
    "        if mask is not None:\n",
    "            if mask.dim() == 2:\n",
    "                mask = mask.unsqueeze(1)\n",
    "            attn = attn.masked_fill(mask, -1e10)\n",
    "        attn = self.dropout(self.softmax(attn))\n",
    "        output = torch.bmm(attn, v)\n",
    "        return output, attn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.std_dims = StandardizeDimensions()\n",
    "        self.n_head = n_head\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        \n",
    "        self.w_qs = nn.Linear(d_model, n_head * d_k, bias=False)\n",
    "        self.w_ks = nn.Linear(d_model, n_head * d_k, bias=False)\n",
    "        self.w_vs = nn.Linear(d_model, n_head * d_v, bias=False)\n",
    "        nn.init.normal_(self.w_qs.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_k)))\n",
    "        nn.init.normal_(self.w_ks.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_k)))\n",
    "        nn.init.normal_(self.w_vs.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_v)))\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(temperature=np.power(d_k, 0.5), attn_dropout=dropout)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.fc = nn.Linear(n_head * d_v, d_model)\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        # Standardize input dims to at least 3D: [batch, seq_len, features]\n",
    "        q, k, v = self.std_dims([q, k, v], min_dims=3)\n",
    "        mask = self.std_dims(mask, min_dims=3) if mask is not None else None\n",
    "\n",
    "        residual = q\n",
    "        batch_size, len_q, _ = q.size()\n",
    "        len_k = k.size(1)\n",
    "\n",
    "        # Linear projections and reshape for multi-head attention\n",
    "        q = self.w_qs(q).view(batch_size, len_q, self.n_head, self.d_k)\n",
    "        k = self.w_ks(k).view(batch_size, len_k, self.n_head, self.d_k)\n",
    "        v = self.w_vs(v).view(batch_size, len_k, self.n_head, self.d_v)\n",
    "\n",
    "        # Permute and reshape for batch matrix multiplication\n",
    "        q = q.permute(2, 0, 1, 3).contiguous().view(-1, len_q, self.d_k)\n",
    "        k = k.permute(2, 0, 1, 3).contiguous().view(-1, len_k, self.d_k)\n",
    "        v = v.permute(2, 0, 1, 3).contiguous().view(-1, len_k, self.d_v)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.repeat(self.n_head, 1, 1)\n",
    "\n",
    "        output, attn = self.attention(q, k, v, mask=mask)\n",
    "\n",
    "        # Reshape back to [batch, seq_len, n_head * d_v]\n",
    "        output = output.view(self.n_head, batch_size, len_q, self.d_v)\n",
    "        output = output.permute(1, 2, 0, 3).contiguous().view(batch_size, len_q, -1)\n",
    "\n",
    "        output = self.dropout(self.fc(output))\n",
    "        return self.layer_norm(output + residual), attn\n",
    "\n",
    "\n",
    "class TimeEncode(nn.Module):\n",
    "    def __init__(self, expand_dim, factor=5):\n",
    "        super().__init__()\n",
    "        self.factor = factor\n",
    "        self.basis_freq = nn.Parameter((torch.from_numpy(1 / 10 ** np.linspace(0, 9, expand_dim))).float())\n",
    "        self.phase = nn.Parameter(torch.zeros(expand_dim).float())\n",
    "\n",
    "    def forward(self, ts):\n",
    "        if ts.dim() == 1:\n",
    "            ts = ts.unsqueeze(-1)\n",
    "        ts = ts.view(ts.size(0), ts.size(1), 1)\n",
    "        map_ts = ts * self.basis_freq.view(1, 1, -1) + self.phase.view(1, 1, -1)\n",
    "        return torch.cos(map_ts)\n",
    "\n",
    "\n",
    "class PosEncode(nn.Module):\n",
    "    def __init__(self, expand_dim, seq_len):\n",
    "        super().__init__()\n",
    "        self.pos_embeddings = nn.Embedding(seq_len, expand_dim)\n",
    "        \n",
    "    def forward(self, ts):\n",
    "        if ts.dim() == 1:\n",
    "            ts = ts.unsqueeze(-1)\n",
    "        order = ts.argsort(dim=1)\n",
    "        return self.pos_embeddings(order)\n",
    "\n",
    "\n",
    "class LSTMPool(nn.Module):\n",
    "    def __init__(self, feat_dim, edge_dim, time_dim):\n",
    "        super().__init__()\n",
    "        self.feat_dim = feat_dim\n",
    "        self.time_dim = time_dim\n",
    "        self.edge_dim = edge_dim\n",
    "        self.att_dim = feat_dim + edge_dim + time_dim\n",
    "        self.act = nn.ReLU()\n",
    "        self.lstm = nn.LSTM(input_size=self.att_dim, hidden_size=feat_dim, num_layers=1, batch_first=True)\n",
    "        self.merger = MergeLayer(feat_dim, feat_dim, feat_dim, feat_dim)\n",
    "\n",
    "    def forward(self, src, src_t, seq, seq_t, seq_e, mask):\n",
    "        if seq.dim() == 2:\n",
    "            seq = seq.unsqueeze(1)\n",
    "        if seq_t.dim() == 2:\n",
    "            seq_t = seq_t.unsqueeze(1)\n",
    "        seq_x = torch.cat([seq, seq_t], dim=2)\n",
    "        _, (hn, _) = self.lstm(seq_x)\n",
    "        return self.merger(hn[-1], src), None\n",
    "\n",
    "\n",
    "class MeanPool(nn.Module):\n",
    "    def __init__(self, feat_dim, edge_dim):\n",
    "        super().__init__()\n",
    "        self.edge_dim = edge_dim\n",
    "        self.feat_dim = feat_dim\n",
    "        self.act = nn.ReLU()\n",
    "        self.merger = MergeLayer(edge_dim + feat_dim, feat_dim, feat_dim, feat_dim)\n",
    "        \n",
    "    def forward(self, src, src_t, seq, seq_t, seq_e, mask):\n",
    "        if seq.dim() == 2:\n",
    "            seq = seq.unsqueeze(1)\n",
    "        if seq_e.dim() == 2:\n",
    "            seq_e = seq_e.unsqueeze(1)\n",
    "        seq_x = torch.cat([seq, seq_e], dim=2)\n",
    "        return self.merger(seq_x.mean(dim=1), src), None\n",
    "\n",
    "\n",
    "class AttnModel(nn.Module):\n",
    "    def __init__(self, feat_dim, edge_dim, time_dim, n_head=2, drop_out=0.1):\n",
    "        super().__init__()\n",
    "        self.feat_dim = feat_dim\n",
    "        self.time_dim = time_dim\n",
    "        self.edge_in_dim = feat_dim + edge_dim + time_dim\n",
    "        self.model_dim = self.edge_in_dim\n",
    "        self.std_dims = StandardizeDimensions()\n",
    "        self.merger = MergeLayer(self.model_dim, feat_dim, feat_dim, feat_dim)\n",
    "        assert self.model_dim % n_head == 0\n",
    "\n",
    "        self.multi_head_target = MultiHeadAttention(\n",
    "            n_head=n_head,\n",
    "            d_model=self.model_dim,\n",
    "            d_k=self.model_dim // n_head,\n",
    "            d_v=self.model_dim // n_head,\n",
    "            dropout=drop_out\n",
    "        )\n",
    "        self.dropout = nn.Dropout(drop_out)\n",
    "\n",
    "    def forward(self, src, src_t, seq, seq_t, seq_e, mask):\n",
    "        src = self.std_dims(src, min_dims=3)\n",
    "        src_t = self.std_dims(src_t, min_dims=3)\n",
    "        seq = self.std_dims(seq, min_dims=3)\n",
    "        seq_t = self.std_dims(seq_t, min_dims=3)\n",
    "        seq_e = self.std_dims(seq_e, min_dims=3)\n",
    "\n",
    "        seq_len = seq.size(1)\n",
    "        assert seq_t.size(1) == seq_len\n",
    "        assert seq_e.size(1) == seq_len\n",
    "\n",
    "        q = torch.cat([src, src_t], dim=-1)\n",
    "        k = torch.cat([seq, seq_t, seq_e], dim=-1)\n",
    "\n",
    "        output, attn = self.multi_head_target(q=q, k=k, v=k, mask=mask)\n",
    "        return self.merger(output.squeeze(1), src.squeeze(1)), attn\n",
    "\n",
    "\n",
    "class TGAN(torch.nn.Module):\n",
    "    def __init__(self, ngh_finder,n_feat, e_feat, use_time='time', agg_method='attn',\n",
    "                 node_dim=None, time_dim=None, num_layers=3, n_head=1,\n",
    "                 null_idx=0, num_heads=1, drop_out=0.1, seq_len=None):\n",
    "        super(TGAN, self).__init__()\n",
    "        \n",
    "        self.raw_feat_dim = n_feat.shape[1]\n",
    "        self.n_feat = torch.nn.Parameter(torch.tensor(n_feat, dtype=torch.float32))\n",
    "        \n",
    "        \n",
    "        self.node_raw_embed = torch.nn.Embedding.from_pretrained(\n",
    "        self.n_feat, padding_idx=0, freeze=True)\n",
    "        self.feat_dim = max(64, self.raw_feat_dim)\n",
    "        \n",
    "        if self.raw_feat_dim != self.feat_dim:\n",
    "            self.proj = nn.Sequential(\n",
    "                nn.Linear(self.raw_feat_dim, self.feat_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            self.proj = torch.nn.Identity()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.ngh_finder = ngh_finder\n",
    "        self.null_idx = null_idx\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.n_feat_dim = self.feat_dim\n",
    "        self.e_feat_dim = 0 if e_feat is None else e_feat.shape[1]\n",
    "        self.model_dim = self.feat_dim + 1\n",
    "        self.use_time = use_time\n",
    "        self.merge_layer = MergeLayer(self.feat_dim, self.feat_dim, self.feat_dim, self.feat_dim)\n",
    "\n",
    "        if agg_method == 'attn':\n",
    "            self.attn_model_list = nn.ModuleList([\n",
    "                AttnModel(self.feat_dim, 0, self.feat_dim, n_head=n_head, drop_out=drop_out)\n",
    "                for _ in range(num_layers)\n",
    "            ])\n",
    "        elif agg_method == 'lstm':\n",
    "            self.attn_model_list = nn.ModuleList([\n",
    "                LSTMPool(self.feat_dim, self.feat_dim, self.feat_dim)\n",
    "                for _ in range(num_layers)\n",
    "            ])\n",
    "        elif agg_method == 'mean':\n",
    "            self.attn_model_list = nn.ModuleList([\n",
    "                MeanPool(self.feat_dim, self.feat_dim)\n",
    "                for _ in range(num_layers)\n",
    "            ])\n",
    "\n",
    "        if use_time == 'time':\n",
    "            self.time_encoder = TimeEncode(expand_dim=self.feat_dim)\n",
    "        elif use_time == 'pos':\n",
    "            self.time_encoder = PosEncode(expand_dim=self.feat_dim, seq_len=seq_len)\n",
    "\n",
    "        self.pi = PersistenceImage(bandwidth=0.1, weight=lambda x: x[1], im_range=[0, 1, 0, 1],\n",
    "                                   resolution=[10, 10])\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.feat_dim + 100, self.feat_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_out),\n",
    "            nn.Linear(self.feat_dim // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, *args):\n",
    "        return self.forward_graph_classification(*args)\n",
    "\n",
    "    def forward_graph_classification(self, batch):\n",
    "        device = self.n_feat.device\n",
    "        src_idx_l = torch.arange(batch.num_nodes, device=device, dtype=torch.long)\n",
    "        cut_time_l = torch.zeros(batch.num_nodes, device=device, dtype=torch.float32)\n",
    "        \n",
    "        node_embeddings = self.proj(self.tem_conv(src_idx_l, cut_time_l, self.num_layers))\n",
    "        graph_embeddings = global_mean_pool(node_embeddings, batch.batch)\n",
    "        \n",
    "        # Use existing PI vectors stored in batch.pi, assumed shape [num_graphs, 400]\n",
    "        pi_tensor = batch.pi.to(device).float()\n",
    "        \n",
    "        combined = torch.cat([graph_embeddings, pi_tensor], dim=1)\n",
    "        return self.classifier(combined)\n",
    "\n",
    "\n",
    "    def tem_conv(self, src_idx_l, cut_time_l, curr_layers, num_neighbors=20):\n",
    "        if cut_time_l.dim() == 1:\n",
    "            cut_time_l = cut_time_l.unsqueeze(-1)\n",
    "\n",
    "        raw_embed = self.node_raw_embed(src_idx_l)\n",
    "        src_node_feat = self.proj(raw_embed)\n",
    "        if curr_layers == 0:\n",
    "            return src_node_feat\n",
    "\n",
    "        src_node_conv_feat = self.tem_conv(\n",
    "            src_idx_l, \n",
    "            cut_time_l, \n",
    "            curr_layers - 1,\n",
    "            num_neighbors\n",
    "        )\n",
    "\n",
    "        src_ngh_node_batch, _ = self.ngh_finder.get_temporal_neighbor(\n",
    "            src_idx_l, \n",
    "            cut_time_l.squeeze(-1),  \n",
    "            num_neighbors=num_neighbors\n",
    "        )\n",
    "\n",
    "        src_ngh_node_batch_th = src_ngh_node_batch.long().flatten()\n",
    "\n",
    "        src_ngh_feat = self.tem_conv(\n",
    "            src_ngh_node_batch.flatten(),\n",
    "            cut_time_l.repeat_interleave(num_neighbors, dim=0),\n",
    "            curr_layers - 1,\n",
    "            num_neighbors\n",
    "        ).view(src_idx_l.size(0), num_neighbors, -1)\n",
    "\n",
    "        src_ngh_t_embed = self.time_encoder(cut_time_l - cut_time_l.mean())\n",
    "\n",
    "        if src_ngh_t_embed.dim() == 2:\n",
    "            src_ngh_t_embed = src_ngh_t_embed.unsqueeze(1)\n",
    "        src_ngh_t_embed = src_ngh_t_embed.expand(-1, num_neighbors, -1)\n",
    "\n",
    "        mask = src_ngh_node_batch == 0\n",
    "        \n",
    "        local, _ = self.attn_model_list[curr_layers - 1](\n",
    "            src_node_conv_feat.unsqueeze(1),\n",
    "            self.time_encoder(torch.zeros_like(cut_time_l)),\n",
    "            src_ngh_feat,\n",
    "            src_ngh_t_embed,\n",
    "            torch.zeros_like(src_ngh_feat[..., :0]),\n",
    "            mask.unsqueeze(1)\n",
    "        )\n",
    "        \n",
    "        return local.squeeze(1)\n",
    "\n",
    "\n",
    "class NeighborFinder:\n",
    "    def __init__(self, adj_list, uniform=False):\n",
    "        self.node_idx_l, self.node_ts_l, self.edge_idx_l, self.off_set_l = self.init_off_set(adj_list)\n",
    "        self.uniform = uniform\n",
    "        self.pi = PersistenceImage(bandwidth=0.1, weight=lambda x: x[1], im_range=[0, 1, 0, 1],\n",
    "                                   resolution=[10, 10]) \n",
    "\n",
    "    def init_off_set(self, adj_list):\n",
    "        n_idx_l, n_ts_l, e_idx_l = [], [], []\n",
    "        off_set_l = [0]\n",
    "        for i in range(len(adj_list)):\n",
    "            curr = sorted(adj_list[i], key=lambda x: x[1])\n",
    "            n_idx_l.extend([x[0] for x in curr])\n",
    "            e_idx_l.extend([x[1] for x in curr])\n",
    "            n_ts_l.extend([x[2] for x in curr])\n",
    "            off_set_l.append(len(n_idx_l))\n",
    "        return torch.tensor(n_idx_l), torch.tensor(n_ts_l), torch.tensor(e_idx_l), torch.tensor(off_set_l)\n",
    "\n",
    "    def find_before(self, src_idx, cut_time):\n",
    "        start = self.off_set_l[src_idx]\n",
    "        end = self.off_set_l[src_idx + 1]\n",
    "        neighbors_ts = self.node_ts_l[start:end]\n",
    "        mask = neighbors_ts < cut_time\n",
    "        return self.node_idx_l[start:end][mask], self.edge_idx_l[start:end][mask], neighbors_ts[mask]\n",
    "\n",
    "    def get_temporal_neighbor(self, src_idx_l, cut_time_l, num_neighbors=20):\n",
    "        if src_idx_l.is_cuda or cut_time_l.is_cuda:\n",
    "            device = src_idx_l.device\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "\n",
    "        out_ngh_node = torch.zeros((len(src_idx_l), num_neighbors), dtype=torch.long, device=device)\n",
    "        out_ngh_t = torch.zeros((len(src_idx_l), num_neighbors), dtype=torch.float, device=device)\n",
    "\n",
    "        for i in range(len(src_idx_l)):\n",
    "            src_idx = src_idx_l[i].item()\n",
    "            cut_time = cut_time_l[i].item()\n",
    "            ngh_idx, _, ngh_ts = self.find_before(src_idx, cut_time)\n",
    "            if len(ngh_idx) > 0:\n",
    "                sampled = ngh_idx[:num_neighbors]\n",
    "                sampled_ts = ngh_ts[:num_neighbors]\n",
    "                out_ngh_node[i, -len(sampled):] = sampled\n",
    "                out_ngh_t[i, -len(sampled_ts):] = sampled_ts\n",
    "        return out_ngh_node, out_ngh_t\n",
    "\n",
    "\n",
    "class GraphClassifier(torch.nn.Module):\n",
    "    def __init__(self, dim, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.fc_1 = torch.nn.Linear(dim, 80)\n",
    "        self.fc_2 = torch.nn.Linear(80, 10)\n",
    "        self.fc_3 = torch.nn.Linear(10, 1)\n",
    "        self.act = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(p=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        x = self.act(self.fc_1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.act(self.fc_2(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc_3(x).flatten()\n",
    "\n",
    "\n",
    "def build_neighbor_finder(dataset):\n",
    "    src_all, dst_all, eidx_all, ts_all = [], [], [], []\n",
    "    offset = 0\n",
    "    node_offset = 0\n",
    "\n",
    "    for data in dataset:\n",
    "        n_nodes = data.num_nodes\n",
    "        edges = data.edge_index.cpu().numpy()\n",
    "        node_timestamps = data.x[:, 1].cpu().numpy()\n",
    "        edge_timestamps = np.minimum(node_timestamps[edges[0]], node_timestamps[edges[1]])\n",
    "        edge_indices = np.arange(offset, offset + edges.shape[1])\n",
    "        src_all.append(edges[0] + node_offset)\n",
    "        dst_all.append(edges[1] + node_offset)\n",
    "        eidx_all.append(edge_indices)\n",
    "        ts_all.append(edge_timestamps)\n",
    "        offset += edges.shape[1]\n",
    "        node_offset += n_nodes\n",
    "\n",
    "    src_all = np.concatenate(src_all)\n",
    "    dst_all = np.concatenate(dst_all)\n",
    "    eidx_all = np.concatenate(eidx_all)\n",
    "    ts_all = np.concatenate(ts_all)\n",
    "\n",
    "    max_node = max(np.max(src_all), np.max(dst_all)) if len(src_all) > 0 else 0\n",
    "    adjacency_list = [[] for _ in range(max_node + 1)]\n",
    "\n",
    "    for s, d, eidx, ts in zip(src_all, dst_all, eidx_all, ts_all):\n",
    "        adjacency_list[s].append((d, eidx, ts))\n",
    "        adjacency_list[d].append((s, eidx, ts))\n",
    "\n",
    "    nf = NeighborFinder(adjacency_list, uniform=False)\n",
    "    nf.pi = PersistenceImage(bandwidth=0.1, weight=lambda x: x[1],\n",
    "                             im_range=[0, 1, 0, 1], resolution=[10, 10])  \n",
    "    return nf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bde0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ab74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "\n",
    "def eval_epoch_metrics(tgan, classifier, loader, device, n_layer):\n",
    "    tgan.eval()\n",
    "    classifier.eval()\n",
    "    y_true, y_pred_logits = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            src_idx_l = torch.arange(batch.num_nodes, device=device).long()\n",
    "            cut_time_l = torch.zeros(batch.num_nodes, device=device).float()\n",
    "            node_emb = tgan.tem_conv(src_idx_l, cut_time_l, curr_layers=n_layer)\n",
    "            graph_emb = global_mean_pool(node_emb, batch.batch)\n",
    "\n",
    "            pi_vecs = torch.stack([g.pi for g in batch.to_data_list()]).to(device)\n",
    "            combined_emb = torch.cat([graph_emb, pi_vecs], dim=1)\n",
    "\n",
    "            logits = classifier(combined_emb)\n",
    "            y_true.append(batch.y.cpu().numpy())\n",
    "            y_pred_logits.append(logits.cpu().numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred_logits = np.concatenate(y_pred_logits)\n",
    "    y_pred = (y_pred_logits > 0).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred_logits)\n",
    "\n",
    "    return acc, f1, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d26e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "def run_training_multiple_runs_tgat(train_loader, val_loader, test_loader,\n",
    "                                    n_epoch=100, n_layer=2, lr=3e-4,\n",
    "                                    drop_out=0.1,\n",
    "                                    num_runs=5, seed_base=42, patience=20,\n",
    "                                    checkpoint_dir=None, min_delta=0.001):\n",
    "    \n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if checkpoint_dir is None:\n",
    "        checkpoint_dir = \"tgat_checkpoints\"\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    all_test_metrics = []\n",
    "    all_val_metrics = []\n",
    "\n",
    "    # Precompute neighbor finder & node features\n",
    "    train_ngh_finder = build_neighbor_finder(train_loader.dataset)\n",
    "    node_features = torch.cat([data.x for data in train_loader.dataset], dim=0)\n",
    "    node_features = node_features.detach().clone().float()  # safe for Parameter\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        seed = seed_base + run\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "        tgat = TGAN(\n",
    "            ngh_finder=train_ngh_finder,  \n",
    "            n_feat=node_features.numpy(),\n",
    "            e_feat=None,\n",
    "            use_time='time',\n",
    "            agg_method='attn',\n",
    "            num_layers=2,\n",
    "            n_head=4,\n",
    "            drop_out=0.1\n",
    "        ).to(device)\n",
    "\n",
    "        \n",
    "\n",
    "        classifier = GraphClassifier(dim=tgat.feat_dim + 400, drop=drop_out).to(device)\n",
    "        optimizer = torch.optim.Adam(classifier.parameters(), lr=lr)\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "        print(f\"\\n--- Run {run+1}/{num_runs} (Seed: {seed}) ---\")\n",
    "\n",
    "  \n",
    "        dummy_src = torch.arange(10, device=device)\n",
    "        dummy_time = torch.zeros(10, device=device)\n",
    "        with torch.no_grad():\n",
    "            _ = tgat.tem_conv(dummy_src, dummy_time, curr_layers=n_layer)\n",
    "\n",
    "        # --- Initialize best metrics ---\n",
    "        best_val_auc = 0\n",
    "        best_test_metrics = {'acc': 0, 'f1': 0, 'auc': 0}\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        # --- Check for existing checkpoint to resume ---\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'run_{run}_best.pth')\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "            best_val_auc = checkpoint.get('best_val_auc', 0)\n",
    "            best_test_metrics = checkpoint.get('best_test_metrics', {'acc':0,'f1':0,'auc':0})\n",
    "            print(f\"Resuming run {run} from checkpoint: best_val_auc={best_val_auc:.4f}\")\n",
    "\n",
    "        for epoch in range(n_epoch):\n",
    "            # Training\n",
    "            total_loss = 0\n",
    "            tgat.eval()\n",
    "            classifier.train()\n",
    "            for batch in train_loader:\n",
    "                batch = batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                src_idx = torch.arange(batch.num_nodes, device=device)\n",
    "                cut_time = torch.zeros(batch.num_nodes, device=device)\n",
    "                node_emb = tgat.tem_conv(src_idx, cut_time, curr_layers=n_layer)\n",
    "                graph_emb = global_mean_pool(node_emb, batch.batch)\n",
    "                pi_vecs = torch.stack([g.pi for g in batch.to_data_list()]).to(device)\n",
    "                combined_emb = torch.cat([graph_emb, pi_vecs], dim=1)\n",
    "\n",
    "                logits = classifier(combined_emb)\n",
    "                loss = criterion(logits, batch.y.float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item() * getattr(batch, \"num_graphs\", batch.y.size(0))\n",
    "\n",
    "            train_loss = total_loss / len(train_loader.dataset)\n",
    "\n",
    "            # Validation & Test\n",
    "            val_acc, val_f1, val_auc = eval_epoch_metrics(tgat, classifier, val_loader, device, n_layer)\n",
    "            test_acc, test_f1, test_auc = eval_epoch_metrics(tgat, classifier, test_loader, device, n_layer)\n",
    "            print(f\"Epoch {epoch}: Train Loss: {train_loss:.4f} | Val AUC: {val_auc:.4f} | Test AUC: {test_auc:.4f}\")\n",
    "\n",
    "            # --- Save every epoch (for crash recovery) ---\n",
    "            torch.save({\n",
    "              'tgat_state_dict': tgat.state_dict(),\n",
    "              'classifier_state_dict': classifier.state_dict(),\n",
    "              'optimizer_state_dict': optimizer.state_dict(),\n",
    "              'best_val_auc': best_val_auc,\n",
    "              'best_test_metrics': best_test_metrics,\n",
    "              'epoch': epoch\n",
    "          }, checkpoint_path)\n",
    "\n",
    "            # --- Save best model ---\n",
    "            if val_auc > best_val_auc + min_delta:\n",
    "                best_val_auc = val_auc\n",
    "                best_test_metrics = {'acc': test_acc, 'f1': test_f1, 'auc': test_auc}\n",
    "                epochs_no_improve = 0\n",
    "                torch.save({\n",
    "                    'classifier_state_dict': classifier.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'best_val_auc': best_val_auc,\n",
    "                    'best_test_metrics': best_test_metrics,\n",
    "                    'epoch': epoch\n",
    "                }, checkpoint_path)\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "\n",
    "            # Early stopping\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch} for run {run+1}\")\n",
    "                break\n",
    "\n",
    "        # Load best model for final evaluation\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        best_val_auc = checkpoint['best_val_auc']\n",
    "        best_test_metrics = checkpoint['best_test_metrics']\n",
    "\n",
    "        all_val_metrics.append(best_val_auc)\n",
    "        all_test_metrics.append(best_test_metrics)\n",
    "\n",
    "        del tgat, classifier, optimizer\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Aggregate metrics\n",
    "    test_accs = np.array([m['acc'] for m in all_test_metrics])\n",
    "    test_f1s = np.array([m['f1'] for m in all_test_metrics])\n",
    "    test_aucs = np.array([m['auc'] for m in all_test_metrics])\n",
    "\n",
    "    results = {\n",
    "        'mean_test_acc': float(test_accs.mean()),\n",
    "        'std_test_acc': float(test_accs.std()),\n",
    "        'mean_test_f1': float(test_f1s.mean()),\n",
    "        'std_test_f1': float(test_f1s.std()),\n",
    "        'mean_test_auc': float(test_aucs.mean()),\n",
    "        'std_test_auc': float(test_aucs.std())\n",
    "    }\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FINAL SUMMARY OVER {num_runs} RUNS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Accuracy: {results['mean_test_acc']*100:.2f}% ± {results['std_test_acc']*100:.2f}%\")\n",
    "    print(f\"F1 Score: {results['mean_test_f1']*100:.2f}% ± {results['std_test_f1']*100:.2f}%\")\n",
    "    print(f\"AUC:      {results['mean_test_auc']*100:.2f}% ± {results['std_test_auc']*100:.2f}%\")\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe6dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with all features\n",
    "results = run_training_multiple_runs_tgat(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    n_epoch=100,\n",
    "    n_layer=2,\n",
    "    lr=1e-3,\n",
    "    drop_out=0.1,\n",
    "    num_runs=10,\n",
    "    seed_base=42,\n",
    "    patience=20,\n",
    "    min_delta=0.001,\n",
    "    checkpoint_dir=None\n",
    ")\n",
    "\n",
    "print(f\"Final Results: {results['mean_test_auc']:.4f} ± {results['std_test_auc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9f54f9",
   "metadata": {},
   "source": [
    "## Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fec270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "filepath = \"../collection/graphs/networkx/concrete/graphs_concrete.pkl\"\n",
    "\n",
    "\n",
    "with open(filepath, 'rb') as f:\n",
    "    graphs_concrete_ablation = pickle.load(f)\n",
    "print(f\"Loaded {len(graphs_concrete_ablation)} graphs from {filepath}\")\n",
    "\n",
    "\n",
    "filepath = '../collection/graphs/networkx/rocky/graphs_rocky.pkl'\n",
    "\n",
    "\n",
    "with open(filepath, 'rb') as f:\n",
    "    graphs_rocky_ablation = pickle.load(f)\n",
    "print(f\"Loaded {len(graphs_rocky_ablation)} graphs from {filepath}\")\n",
    "\n",
    "graphs_concrete_pyg_ablation = convert_nx_to_pyg(graphs_concrete_ablation)\n",
    "graphs_rocky_pyg_ablation = convert_nx_to_pyg(graphs_rocky_ablation)\n",
    "\n",
    "graphs_concrete_pyg_ablation = remap_node_indices(graphs_concrete_pyg_ablation)\n",
    "graphs_rocky_pyg_ablation = remap_node_indices(graphs_rocky_pyg_ablation)\n",
    "\n",
    "graphs_concrete_pyg_ablation = add_graph_labels(graphs_concrete_pyg_ablation, label=0)\n",
    "graphs_rocky_pyg_ablation = add_graph_labels(graphs_rocky_pyg_ablation, label=1)\n",
    "\n",
    "def combine_graphs(graphs_label_dict):\n",
    "    all_graphs = []\n",
    "    for graphs in graphs_label_dict.values():\n",
    "        all_graphs.extend(graphs)\n",
    "    return all_graphs\n",
    "\n",
    "graphs_dict_with_labels_ablation = {\n",
    "    0: graphs_concrete_pyg_ablation,  # label 0\n",
    "    1: graphs_rocky_pyg_ablation      # label 1\n",
    "}\n",
    "\n",
    "all_graphs_ablation = combine_graphs(graphs_dict_with_labels_ablation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eda1c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "splits_ablation = split_graphs(all_graphs_ablation, test_size=0.2, val_size=0.25, random_state=42)\n",
    "\n",
    "train_graphs_ablation = splits_ablation[\"train\"]\n",
    "val_graphs_ablation = splits_ablation[\"val\"]\n",
    "test_graphs_ablation = splits_ablation[\"test\"]\n",
    "\n",
    "print(f\"Train: {len(train_graphs_ablation)}\")\n",
    "print(f\"Validation: {len(val_graphs_ablation)}\")\n",
    "print(f\"Test: {len(test_graphs_ablation)}\")\n",
    "\n",
    "sample_ablation = train_graphs_ablation[0]\n",
    "print(f\"Node dim: {sample_ablation.x.shape}\")  \n",
    "print(type(all_graphs_ablation[0]))\n",
    "print(all_graphs_ablation[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3dbdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "train_loader_ablation = DataLoader(train_graphs_ablation, batch_size=4, shuffle=True)\n",
    "val_loader_ablation = DataLoader(val_graphs_ablation, batch_size=4)\n",
    "test_loader_ablation = DataLoader(test_graphs_ablation, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd45bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_ablation = train_loader_ablation.dataset[0]\n",
    "print(\"Standard attributes via keys():\", graph_ablation.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c664083",
   "metadata": {},
   "source": [
    "## TGAT without PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0d99cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "class StandardizeDimensions(nn.Module):\n",
    "    \"\"\"Ensures inputs are always [batch, seq_len, features] or [batch, features]\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x, min_dims=2):\n",
    "        if isinstance(x, (list, tuple)):\n",
    "            return [self.forward(tensor, min_dims) for tensor in x]\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x)\n",
    "        while x.dim() < min_dims:\n",
    "            x = x.unsqueeze(0)\n",
    "        if x.dim() == 2:\n",
    "            return x.unsqueeze(1) if min_dims >= 3 else x\n",
    "        elif x.dim() == 3:  \n",
    "            return x\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected shape {x.shape}. Max 3D tensors supported\")\n",
    "\n",
    "\n",
    "class MergeLayer(nn.Module):\n",
    "    def __init__(self, dim1, dim2, dim3, dim4):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim1 + dim2, dim3)\n",
    "        self.fc2 = nn.Linear(dim3, dim4)\n",
    "        self.act = nn.ReLU()\n",
    "        nn.init.xavier_normal_(self.fc1.weight)\n",
    "        nn.init.xavier_normal_(self.fc2.weight)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        h = self.act(self.fc1(x))\n",
    "        return self.fc2(h)\n",
    "\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, temperature, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        if q.dim() == 2:\n",
    "            q = q.unsqueeze(1)\n",
    "        if k.dim() == 2:\n",
    "            k = k.unsqueeze(1)\n",
    "        if v.dim() == 2:\n",
    "            v = v.unsqueeze(1)\n",
    "            \n",
    "        attn = torch.bmm(q, k.transpose(1, 2)) / self.temperature\n",
    "        if mask is not None:\n",
    "            if mask.dim() == 2:\n",
    "                mask = mask.unsqueeze(1)\n",
    "            attn = attn.masked_fill(mask, -1e10)\n",
    "        attn = self.dropout(self.softmax(attn))\n",
    "        output = torch.bmm(attn, v)\n",
    "        return output, attn\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.std_dims = StandardizeDimensions()\n",
    "        self.n_head = n_head\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        \n",
    "        self.w_qs = nn.Linear(d_model, n_head * d_k, bias=False)\n",
    "        self.w_ks = nn.Linear(d_model, n_head * d_k, bias=False)\n",
    "        self.w_vs = nn.Linear(d_model, n_head * d_v, bias=False)\n",
    "        nn.init.normal_(self.w_qs.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_k)))\n",
    "        nn.init.normal_(self.w_ks.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_k)))\n",
    "        nn.init.normal_(self.w_vs.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_v)))\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(temperature=np.power(d_k, 0.5), attn_dropout=dropout)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.fc = nn.Linear(n_head * d_v, d_model)\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        # Standardize input dims to at least 3D: [batch, seq_len, features]\n",
    "        q, k, v = self.std_dims([q, k, v], min_dims=3)\n",
    "        mask = self.std_dims(mask, min_dims=3) if mask is not None else None\n",
    "\n",
    "        residual = q\n",
    "        batch_size, len_q, _ = q.size()\n",
    "        len_k = k.size(1)\n",
    "\n",
    "        # Linear projections and reshape for multi-head attention\n",
    "        q = self.w_qs(q).view(batch_size, len_q, self.n_head, self.d_k)\n",
    "        k = self.w_ks(k).view(batch_size, len_k, self.n_head, self.d_k)\n",
    "        v = self.w_vs(v).view(batch_size, len_k, self.n_head, self.d_v)\n",
    "\n",
    "        # Permute and reshape for batch matrix multiplication\n",
    "        q = q.permute(2, 0, 1, 3).contiguous().view(-1, len_q, self.d_k)\n",
    "        k = k.permute(2, 0, 1, 3).contiguous().view(-1, len_k, self.d_k)\n",
    "        v = v.permute(2, 0, 1, 3).contiguous().view(-1, len_k, self.d_v)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.repeat(self.n_head, 1, 1)\n",
    "\n",
    "        output, attn = self.attention(q, k, v, mask=mask)\n",
    "\n",
    "        # Reshape back to [batch, seq_len, n_head * d_v]\n",
    "        output = output.view(self.n_head, batch_size, len_q, self.d_v)\n",
    "        output = output.permute(1, 2, 0, 3).contiguous().view(batch_size, len_q, -1)\n",
    "\n",
    "        output = self.dropout(self.fc(output))\n",
    "        return self.layer_norm(output + residual), attn\n",
    "\n",
    "\n",
    "class TimeEncode(nn.Module):\n",
    "    def __init__(self, expand_dim, factor=5):\n",
    "        super().__init__()\n",
    "        self.factor = factor\n",
    "        self.basis_freq = nn.Parameter((torch.from_numpy(1 / 10 ** np.linspace(0, 9, expand_dim))).float())\n",
    "        self.phase = nn.Parameter(torch.zeros(expand_dim).float())\n",
    "\n",
    "    def forward(self, ts):\n",
    "        if ts.dim() == 1:\n",
    "            ts = ts.unsqueeze(-1)\n",
    "        ts = ts.view(ts.size(0), ts.size(1), 1)\n",
    "        map_ts = ts * self.basis_freq.view(1, 1, -1) + self.phase.view(1, 1, -1)\n",
    "        return torch.cos(map_ts)\n",
    "\n",
    "\n",
    "class PosEncode(nn.Module):\n",
    "    def __init__(self, expand_dim, seq_len):\n",
    "        super().__init__()\n",
    "        self.pos_embeddings = nn.Embedding(seq_len, expand_dim)\n",
    "        \n",
    "    def forward(self, ts):\n",
    "        if ts.dim() == 1:\n",
    "            ts = ts.unsqueeze(-1)\n",
    "        order = ts.argsort(dim=1)\n",
    "        return self.pos_embeddings(order)\n",
    "\n",
    "\n",
    "class LSTMPool(nn.Module):\n",
    "    def __init__(self, feat_dim, edge_dim, time_dim):\n",
    "        super().__init__()\n",
    "        self.feat_dim = feat_dim\n",
    "        self.time_dim = time_dim\n",
    "        self.edge_dim = edge_dim\n",
    "        self.att_dim = feat_dim + edge_dim + time_dim\n",
    "        self.act = nn.ReLU()\n",
    "        self.lstm = nn.LSTM(input_size=self.att_dim, hidden_size=feat_dim, num_layers=1, batch_first=True)\n",
    "        self.merger = MergeLayer(feat_dim, feat_dim, feat_dim, feat_dim)\n",
    "\n",
    "    def forward(self, src, src_t, seq, seq_t, seq_e, mask):\n",
    "        if seq.dim() == 2:\n",
    "            seq = seq.unsqueeze(1)\n",
    "        if seq_t.dim() == 2:\n",
    "            seq_t = seq_t.unsqueeze(1)\n",
    "        seq_x = torch.cat([seq, seq_t], dim=2)\n",
    "        _, (hn, _) = self.lstm(seq_x)\n",
    "        return self.merger(hn[-1], src), None\n",
    "\n",
    "\n",
    "class MeanPool(nn.Module):\n",
    "    def __init__(self, feat_dim, edge_dim):\n",
    "        super().__init__()\n",
    "        self.edge_dim = edge_dim\n",
    "        self.feat_dim = feat_dim\n",
    "        self.act = nn.ReLU()\n",
    "        self.merger = MergeLayer(edge_dim + feat_dim, feat_dim, feat_dim, feat_dim)\n",
    "        \n",
    "    def forward(self, src, src_t, seq, seq_t, seq_e, mask):\n",
    "        if seq.dim() == 2:\n",
    "            seq = seq.unsqueeze(1)\n",
    "        if seq_e.dim() == 2:\n",
    "            seq_e = seq_e.unsqueeze(1)\n",
    "        seq_x = torch.cat([seq, seq_e], dim=2)\n",
    "        return self.merger(seq_x.mean(dim=1), src), None\n",
    "\n",
    "\n",
    "class AttnModel(nn.Module):\n",
    "    def __init__(self, feat_dim, edge_dim, time_dim, n_head=2, drop_out=0.1):\n",
    "        super().__init__()\n",
    "        self.feat_dim = feat_dim\n",
    "        self.time_dim = time_dim\n",
    "        self.edge_in_dim = feat_dim + edge_dim + time_dim\n",
    "        self.model_dim = self.edge_in_dim\n",
    "        self.std_dims = StandardizeDimensions()\n",
    "        self.merger = MergeLayer(self.model_dim, feat_dim, feat_dim, feat_dim)\n",
    "        assert self.model_dim % n_head == 0\n",
    "\n",
    "        self.multi_head_target = MultiHeadAttention(\n",
    "            n_head=n_head,\n",
    "            d_model=self.model_dim,\n",
    "            d_k=self.model_dim // n_head,\n",
    "            d_v=self.model_dim // n_head,\n",
    "            dropout=drop_out\n",
    "        )\n",
    "        self.dropout = nn.Dropout(drop_out)\n",
    "\n",
    "    def forward(self, src, src_t, seq, seq_t, seq_e, mask):\n",
    "        src = self.std_dims(src, min_dims=3)\n",
    "        src_t = self.std_dims(src_t, min_dims=3)\n",
    "        seq = self.std_dims(seq, min_dims=3)\n",
    "        seq_t = self.std_dims(seq_t, min_dims=3)\n",
    "        seq_e = self.std_dims(seq_e, min_dims=3)\n",
    "\n",
    "        seq_len = seq.size(1)\n",
    "        assert seq_t.size(1) == seq_len\n",
    "        assert seq_e.size(1) == seq_len\n",
    "\n",
    "        q = torch.cat([src, src_t], dim=-1)\n",
    "        k = torch.cat([seq, seq_t, seq_e], dim=-1)\n",
    "\n",
    "        output, attn = self.multi_head_target(q=q, k=k, v=k, mask=mask)\n",
    "        return self.merger(output.squeeze(1), src.squeeze(1)), attn\n",
    "\n",
    "\n",
    "class TGAN(torch.nn.Module):\n",
    "    def __init__(self, ngh_finder, n_feat, e_feat, use_time='time', agg_method='attn',\n",
    "                 node_dim=None, time_dim=None, num_layers=3, n_head=1,\n",
    "                 null_idx=0, num_heads=1, drop_out=0.1, seq_len=None):\n",
    "        super(TGAN, self).__init__()\n",
    "        \n",
    "        self.raw_feat_dim = n_feat.shape[1]\n",
    "        self.n_feat = torch.nn.Parameter(torch.tensor(n_feat, dtype=torch.float32))\n",
    "        \n",
    "        self.node_raw_embed = torch.nn.Embedding.from_pretrained(\n",
    "            self.n_feat, padding_idx=0, freeze=True)\n",
    "        self.feat_dim = max(64, self.raw_feat_dim)\n",
    "        \n",
    "        if self.raw_feat_dim != self.feat_dim:\n",
    "            self.proj = nn.Sequential(\n",
    "                nn.Linear(self.raw_feat_dim, self.feat_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            self.proj = torch.nn.Identity()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.ngh_finder = ngh_finder\n",
    "        self.null_idx = null_idx\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.n_feat_dim = self.feat_dim\n",
    "        self.e_feat_dim = 0 if e_feat is None else e_feat.shape[1]\n",
    "        self.model_dim = self.feat_dim + 1\n",
    "        self.use_time = use_time\n",
    "        self.merge_layer = MergeLayer(self.feat_dim, self.feat_dim, self.feat_dim, self.feat_dim)\n",
    "\n",
    "        if agg_method == 'attn':\n",
    "            self.attn_model_list = nn.ModuleList([\n",
    "                AttnModel(self.feat_dim, 0, self.feat_dim, n_head=n_head, drop_out=drop_out)\n",
    "                for _ in range(num_layers)\n",
    "            ])\n",
    "        elif agg_method == 'lstm':\n",
    "            self.attn_model_list = nn.ModuleList([\n",
    "                LSTMPool(self.feat_dim, self.feat_dim, self.feat_dim)\n",
    "                for _ in range(num_layers)\n",
    "            ])\n",
    "        elif agg_method == 'mean':\n",
    "            self.attn_model_list = nn.ModuleList([\n",
    "                MeanPool(self.feat_dim, self.feat_dim)\n",
    "                for _ in range(num_layers)\n",
    "            ])\n",
    "\n",
    "        if use_time == 'time':\n",
    "            self.time_encoder = TimeEncode(expand_dim=self.feat_dim)\n",
    "        elif use_time == 'pos':\n",
    "            self.time_encoder = PosEncode(expand_dim=self.feat_dim, seq_len=seq_len)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.feat_dim, self.feat_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_out),\n",
    "            nn.Linear(self.feat_dim // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, *args):\n",
    "        return self.forward_graph_classification(*args)\n",
    "\n",
    "    def forward_graph_classification(self, batch):\n",
    "        device = self.n_feat.device\n",
    "        src_idx_l = torch.arange(batch.num_nodes, device=device, dtype=torch.long)\n",
    "        cut_time_l = torch.zeros(batch.num_nodes, device=device, dtype=torch.float32)\n",
    "        \n",
    "        node_embeddings = self.proj(self.tem_conv(src_idx_l, cut_time_l, self.num_layers))\n",
    "        graph_embeddings = global_mean_pool(node_embeddings, batch.batch)\n",
    "        \n",
    "        # --- ABLATION: REPLACE real PI with random noise ---\n",
    "        # random noise with the same shape as the real PI features\n",
    "        batch_size = graph_embeddings.size(0)\n",
    "        random_features = torch.randn(batch_size, 400).to(device) # <-- 400 features of noise\n",
    "        combined = torch.cat([graph_embeddings, random_features], dim=1)\n",
    "\n",
    "        \n",
    "        return self.classifier(combined) # Classifier must expect (feat_dim + 400) inputs\n",
    "\n",
    "    def tem_conv(self, src_idx_l, cut_time_l, curr_layers, num_neighbors=20):\n",
    "        if cut_time_l.dim() == 1:\n",
    "            cut_time_l = cut_time_l.unsqueeze(-1)\n",
    "\n",
    "        raw_embed = self.node_raw_embed(src_idx_l)\n",
    "        src_node_feat = self.proj(raw_embed)\n",
    "        if curr_layers == 0:\n",
    "            return src_node_feat\n",
    "\n",
    "        src_node_conv_feat = self.tem_conv(\n",
    "            src_idx_l, \n",
    "            cut_time_l, \n",
    "            curr_layers - 1,\n",
    "            num_neighbors\n",
    "        )\n",
    "\n",
    "        src_ngh_node_batch, _ = self.ngh_finder.get_temporal_neighbor(\n",
    "            src_idx_l, \n",
    "            cut_time_l.squeeze(-1),  \n",
    "            num_neighbors=num_neighbors\n",
    "        )\n",
    "\n",
    "        src_ngh_node_batch_th = src_ngh_node_batch.long().flatten()\n",
    "\n",
    "        src_ngh_feat = self.tem_conv(\n",
    "            src_ngh_node_batch.flatten(),\n",
    "            cut_time_l.repeat_interleave(num_neighbors, dim=0),\n",
    "            curr_layers - 1,\n",
    "            num_neighbors\n",
    "        ).view(src_idx_l.size(0), num_neighbors, -1)\n",
    "\n",
    "        src_ngh_t_embed = self.time_encoder(cut_time_l - cut_time_l.mean())\n",
    "\n",
    "        if src_ngh_t_embed.dim() == 2:\n",
    "            src_ngh_t_embed = src_ngh_t_embed.unsqueeze(1)\n",
    "        src_ngh_t_embed = src_ngh_t_embed.expand(-1, num_neighbors, -1)\n",
    "\n",
    "        mask = src_ngh_node_batch == 0\n",
    "        \n",
    "        local, _ = self.attn_model_list[curr_layers - 1](\n",
    "            src_node_conv_feat.unsqueeze(1),\n",
    "            self.time_encoder(torch.zeros_like(cut_time_l)),\n",
    "            src_ngh_feat,\n",
    "            src_ngh_t_embed,\n",
    "            torch.zeros_like(src_ngh_feat[..., :0]),\n",
    "            mask.unsqueeze(1)\n",
    "        )\n",
    "        \n",
    "        return local.squeeze(1)\n",
    "    \n",
    "class NeighborFinder:\n",
    "    def __init__(self, adj_list, uniform=False):\n",
    "        self.node_idx_l, self.node_ts_l, self.edge_idx_l, self.off_set_l = self.init_off_set(adj_list)\n",
    "        self.uniform = uniform\n",
    "\n",
    "    def init_off_set(self, adj_list):\n",
    "        n_idx_l, n_ts_l, e_idx_l = [], [], []\n",
    "        off_set_l = [0]\n",
    "        for i in range(len(adj_list)):\n",
    "            curr = sorted(adj_list[i], key=lambda x: x[1])\n",
    "            n_idx_l.extend([x[0] for x in curr])\n",
    "            e_idx_l.extend([x[1] for x in curr])\n",
    "            n_ts_l.extend([x[2] for x in curr])\n",
    "            off_set_l.append(len(n_idx_l))\n",
    "        return torch.tensor(n_idx_l), torch.tensor(n_ts_l), torch.tensor(e_idx_l), torch.tensor(off_set_l)\n",
    "\n",
    "    def find_before(self, src_idx, cut_time):\n",
    "        start = self.off_set_l[src_idx]\n",
    "        end = self.off_set_l[src_idx + 1]\n",
    "        neighbors_ts = self.node_ts_l[start:end]\n",
    "        mask = neighbors_ts < cut_time\n",
    "        return self.node_idx_l[start:end][mask], self.edge_idx_l[start:end][mask], neighbors_ts[mask]\n",
    "\n",
    "    def get_temporal_neighbor(self, src_idx_l, cut_time_l, num_neighbors=20):\n",
    "        if src_idx_l.is_cuda or cut_time_l.is_cuda:\n",
    "            device = src_idx_l.device\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "\n",
    "        out_ngh_node = torch.zeros((len(src_idx_l), num_neighbors), dtype=torch.long, device=device)\n",
    "        out_ngh_t = torch.zeros((len(src_idx_l), num_neighbors), dtype=torch.float, device=device)\n",
    "\n",
    "        for i in range(len(src_idx_l)):\n",
    "            src_idx = src_idx_l[i].item()\n",
    "            cut_time = cut_time_l[i].item()\n",
    "            ngh_idx, _, ngh_ts = self.find_before(src_idx, cut_time)\n",
    "            if len(ngh_idx) > 0:\n",
    "                sampled = ngh_idx[:num_neighbors]\n",
    "                sampled_ts = ngh_ts[:num_neighbors]\n",
    "                out_ngh_node[i, -len(sampled):] = sampled\n",
    "                out_ngh_t[i, -len(sampled_ts):] = sampled_ts\n",
    "        return out_ngh_node, out_ngh_t\n",
    "\n",
    "\n",
    "class GraphClassifier(torch.nn.Module):\n",
    "    def __init__(self, dim, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.fc_1 = torch.nn.Linear(dim, 80)\n",
    "        self.fc_2 = torch.nn.Linear(80, 10)\n",
    "        self.fc_3 = torch.nn.Linear(10, 1)\n",
    "        self.act = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(p=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        x = self.act(self.fc_1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.act(self.fc_2(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc_3(x).flatten()\n",
    "\n",
    "\n",
    "def build_neighbor_finder(dataset):\n",
    "    src_all, dst_all, eidx_all, ts_all = [], [], [], []\n",
    "    offset = 0\n",
    "    node_offset = 0\n",
    "\n",
    "    for data in dataset:\n",
    "        n_nodes = data.num_nodes\n",
    "        edges = data.edge_index.cpu().numpy()\n",
    "        node_timestamps = data.x[:, 1].cpu().numpy()\n",
    "        edge_timestamps = np.minimum(node_timestamps[edges[0]], node_timestamps[edges[1]])\n",
    "        edge_indices = np.arange(offset, offset + edges.shape[1])\n",
    "        src_all.append(edges[0] + node_offset)\n",
    "        dst_all.append(edges[1] + node_offset)\n",
    "        eidx_all.append(edge_indices)\n",
    "        ts_all.append(edge_timestamps)\n",
    "        offset += edges.shape[1]\n",
    "        node_offset += n_nodes\n",
    "\n",
    "    src_all = np.concatenate(src_all)\n",
    "    dst_all = np.concatenate(dst_all)\n",
    "    eidx_all = np.concatenate(eidx_all)\n",
    "    ts_all = np.concatenate(ts_all)\n",
    "\n",
    "    max_node = max(np.max(src_all), np.max(dst_all)) if len(src_all) > 0 else 0\n",
    "    adjacency_list = [[] for _ in range(max_node + 1)]\n",
    "\n",
    "    for s, d, eidx, ts in zip(src_all, dst_all, eidx_all, ts_all):\n",
    "        adjacency_list[s].append((d, eidx, ts))\n",
    "        adjacency_list[d].append((s, eidx, ts))\n",
    "\n",
    "    nf = NeighborFinder(adjacency_list, uniform=False)\n",
    "    return nf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8029c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange, tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def eval_epoch_metrics(tgan, classifier, loader, device, n_layer):\n",
    "    tgan.eval()\n",
    "    classifier.eval()\n",
    "    y_true, y_pred_logits = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            src_idx_l = torch.arange(batch.num_nodes, device=device).long()\n",
    "            cut_time_l = torch.zeros(batch.num_nodes, device=device).float()\n",
    "            node_emb = tgan.tem_conv(src_idx_l, cut_time_l, curr_layers=n_layer)\n",
    "            graph_emb = global_mean_pool(node_emb, batch.batch)\n",
    "\n",
    "            # Modified: Remove PI vector processing and concatenation\n",
    "            logits = classifier(graph_emb)\n",
    "            y_true.append(batch.y.cpu().numpy())\n",
    "            y_pred_logits.append(logits.cpu().numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred_logits = np.concatenate(y_pred_logits)\n",
    "    y_pred = (y_pred_logits > 0).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred_logits)\n",
    "\n",
    "    return acc, f1, auc\n",
    "\n",
    "def run_training_multiple_runs_tgat_ablation(train_loader, val_loader, test_loader,\n",
    "                                    n_epoch=100, n_layer=2, lr=3e-4,\n",
    "                                    drop_out=0.1,\n",
    "                                    num_runs=5, seed_base=42, patience=20,\n",
    "                                    checkpoint_dir=None, min_delta=0.001):\n",
    "    \n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if checkpoint_dir is None:\n",
    "        checkpoint_dir = \"tgat_ablation\"\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    all_test_metrics = []\n",
    "    all_val_metrics = []\n",
    "\n",
    "    # Precompute neighbor finder & node features\n",
    "    train_ngh_finder = build_neighbor_finder(train_loader.dataset)\n",
    "    node_features = torch.cat([data.x for data in train_loader.dataset], dim=0)\n",
    "    node_features = node_features.detach().clone().float()  # safe for Parameter\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        seed = seed_base + run\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "        tgat = TGAN(\n",
    "            ngh_finder=train_ngh_finder,  \n",
    "            n_feat=node_features.numpy(),\n",
    "            e_feat=None,\n",
    "            use_time='time',\n",
    "            agg_method='attn',\n",
    "            num_layers=2,\n",
    "            n_head=4,\n",
    "            drop_out=0.1\n",
    "        ).to(device)\n",
    "\n",
    "        # Modified: Remove +400 from dim since we're not using PI anymore\n",
    "        classifier = GraphClassifier(dim=tgat.feat_dim, drop=drop_out).to(device)\n",
    "        optimizer = torch.optim.Adam(classifier.parameters(), lr=lr)\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "        print(f\"\\n--- Run {run+1}/{num_runs} (Seed: {seed}) ---\")\n",
    "\n",
    "        # Prewarm GPU\n",
    "        dummy_src = torch.arange(10, device=device)\n",
    "        dummy_time = torch.zeros(10, device=device)\n",
    "        with torch.no_grad():\n",
    "            _ = tgat.tem_conv(dummy_src, dummy_time, curr_layers=n_layer)\n",
    "\n",
    "        # --- Initialize best metrics ---\n",
    "        best_val_auc = 0\n",
    "        best_test_metrics = {'acc': 0, 'f1': 0, 'auc': 0}\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        # --- Check for existing checkpoint to resume ---\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'run_{run}_best.pth')\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "            best_val_auc = checkpoint.get('best_val_auc', 0)\n",
    "            best_test_metrics = checkpoint.get('best_test_metrics', {'acc':0,'f1':0,'auc':0})\n",
    "            print(f\"Resuming run {run} from checkpoint: best_val_auc={best_val_auc:.4f}\")\n",
    "\n",
    "        for epoch in range(n_epoch):\n",
    "            # Training\n",
    "            total_loss = 0\n",
    "            tgat.eval()\n",
    "            classifier.train()\n",
    "            for batch in train_loader:\n",
    "                batch = batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                src_idx = torch.arange(batch.num_nodes, device=device)\n",
    "                cut_time = torch.zeros(batch.num_nodes, device=device)\n",
    "                node_emb = tgat.tem_conv(src_idx, cut_time, curr_layers=n_layer)\n",
    "                graph_emb = global_mean_pool(node_emb, batch.batch)\n",
    "                \n",
    "                # Modified: Remove PI vector concatenation\n",
    "                logits = classifier(graph_emb)\n",
    "                loss = criterion(logits, batch.y.float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item() * getattr(batch, \"num_graphs\", batch.y.size(0))\n",
    "\n",
    "            train_loss = total_loss / len(train_loader.dataset)\n",
    "\n",
    "            # Validation & Test\n",
    "            val_acc, val_f1, val_auc = eval_epoch_metrics(tgat, classifier, val_loader, device, n_layer)\n",
    "            test_acc, test_f1, test_auc = eval_epoch_metrics(tgat, classifier, test_loader, device, n_layer)\n",
    "            print(f\"Epoch {epoch}: Train Loss: {train_loss:.4f} | Val AUC: {val_auc:.4f} | Test AUC: {test_auc:.4f}\")\n",
    "\n",
    "            # --- Save every epoch (for crash recovery) ---\n",
    "            torch.save({\n",
    "              'tgat_state_dict': tgat.state_dict(),\n",
    "              'classifier_state_dict': classifier.state_dict(),\n",
    "              'optimizer_state_dict': optimizer.state_dict(),\n",
    "              'best_val_auc': best_val_auc,\n",
    "              'best_test_metrics': best_test_metrics,\n",
    "              'epoch': epoch\n",
    "          }, checkpoint_path)\n",
    "\n",
    "            # --- Save best model ---\n",
    "            if val_auc > best_val_auc + min_delta:\n",
    "                best_val_auc = val_auc\n",
    "                best_test_metrics = {'acc': test_acc, 'f1': test_f1, 'auc': test_auc}\n",
    "                epochs_no_improve = 0\n",
    "                torch.save({\n",
    "                    'classifier_state_dict': classifier.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'best_val_auc': best_val_auc,\n",
    "                    'best_test_metrics': best_test_metrics,\n",
    "                    'epoch': epoch\n",
    "                }, checkpoint_path)\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "\n",
    "            # Early stopping\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch} for run {run+1}\")\n",
    "                break\n",
    "\n",
    "        # Load best model for final evaluation\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        best_val_auc = checkpoint['best_val_auc']\n",
    "        best_test_metrics = checkpoint['best_test_metrics']\n",
    "\n",
    "        all_val_metrics.append(best_val_auc)\n",
    "        all_test_metrics.append(best_test_metrics)\n",
    "\n",
    "        del tgat, classifier, optimizer\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Aggregate metrics\n",
    "    test_accs = np.array([m['acc'] for m in all_test_metrics])\n",
    "    test_f1s = np.array([m['f1'] for m in all_test_metrics])\n",
    "    test_aucs = np.array([m['auc'] for m in all_test_metrics])\n",
    "\n",
    "    results = {\n",
    "        'mean_test_acc': float(test_accs.mean()),\n",
    "        'std_test_acc': float(test_accs.std()),\n",
    "        'mean_test_f1': float(test_f1s.mean()),\n",
    "        'std_test_f1': float(test_f1s.std()),\n",
    "        'mean_test_auc': float(test_aucs.mean()),\n",
    "        'std_test_auc': float(test_aucs.std())\n",
    "    }\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FINAL SUMMARY OVER {num_runs} RUNS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Accuracy: {results['mean_test_acc']*100:.2f}% ± {results['std_test_acc']*100:.2f}%\")\n",
    "    print(f\"F1 Score: {results['mean_test_f1']*100:.2f}% ± {results['std_test_f1']*100:.2f}%\")\n",
    "    print(f\"AUC:      {results['mean_test_auc']*100:.2f}% ± {results['std_test_auc']*100:.2f}%\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07869625",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = run_training_multiple_runs_tgat_ablation(\n",
    "    train_loader=train_loader_ablation,\n",
    "    val_loader=val_loader_ablation,\n",
    "    test_loader=test_loader_ablation,\n",
    "    n_epoch=100,\n",
    "    n_layer=2,\n",
    "    lr=1e-3,\n",
    "    drop_out=0.1,\n",
    "    num_runs=10,\n",
    "    seed_base=42,\n",
    "    patience=15,\n",
    "    min_delta=0.001,\n",
    "    checkpoint_dir=None\n",
    ")\n",
    "\n",
    "print(f\"Final Results: {results['mean_test_auc']:.4f} ± {results['std_test_auc']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
